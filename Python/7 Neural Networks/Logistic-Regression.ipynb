{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with `autograd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the sigmoid function $S(t) := \\large \\frac{1}{1 + \\exp(-t)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1.0 / (1.0 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `logSigmoid` computes the natural logarithm of the sigmoid function.  The implementation takes care of preventing *overflows* that would occur in a naive implementation for t < -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSigmoid(t):\n",
    "    if t > -100:\n",
    "        return -np.log(1.0 + np.exp(-t))\n",
    "    else:\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exam.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    count  = 0  # line count\n",
    "    Pass   = []\n",
    "    Hours  = []\n",
    "    for row in reader:\n",
    "        if count != 0:  # skip header\n",
    "            Pass .append(float(row[0]))\n",
    "            Hours.append(float(row[1]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Pass)\n",
    "y = 2 * y - 1\n",
    "x = np.array(Hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a feature matrix `X` and a vector `y` of classification outputs, the *log-likelihood function* $\\texttt{ll}(\\textbf{X}, \\textbf{y},\\textbf{w})$ is mathematically defined as follows:\n",
    "$$\\ell\\ell(\\mathbf{X},\\mathbf{y},\\mathbf{w}) = \n",
    " \\sum\\limits_{i=1}^N \\ln\\Bigl(S\\bigl(y_i \\cdot(\\mathbf{x}_i \\cdot \\mathbf{w})\\bigr)\\Bigr) =\n",
    " \\sum\\limits_{i=1}^N L\\bigl(y_i \\cdot(\\mathbf{x}_i \\cdot \\mathbf{w})\\bigr)\n",
    "$$\n",
    "The value of the *log-likelihood function* is interpreted as the logarithm of the probability that our model of the classifier predicts the observed values $y_i$ when the features are given by the vector $\\textbf{x}_i$ for all $i\\in\\{1,\\cdots,N\\}$.\n",
    "\n",
    "The arguments $\\textbf{X}$, $\\textbf{y}$, and $\\textbf{w}$ are interpreted as follows:\n",
    "* $\\textbf{X}$ is the feature matrix, $\\textbf{X}[i]$ is the $i$-th feature vector, i.e we have\n",
    "  $\\textbf{X}[i] = \\textbf{x}_i$ if we regard $\\textbf{x}_i$ as a row vector.\n",
    "         \n",
    "  Furthermore, it is assumed that $\\textbf{X}[i][0]$ is 1.0 for all $i$.  \n",
    "  Hence we have a feature that is constant for all examples.\n",
    "* $\\textbf{y}$ is the output vector, $\\textbf{y}[i] \\in \\{-1,+1\\}$ for all $i$.\n",
    "* $\\textbf{w}$ is the weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll(w):\n",
    "    ùõº, ùõΩ   = w \n",
    "    result = 0.0\n",
    "    n      = len(x)\n",
    "    for i in range(n):\n",
    "        result = result + logSigmoid(y[i] * (ùõº * x[i] + ùõΩ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradLL = autograd.grad(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll(np.array([0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradLL(np.array([0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaximum(f, gradF, start, eps):\n",
    "    x     = start\n",
    "    fx    = f(x)\n",
    "    alpha = 0.1   # learning rate\n",
    "    cnt   = 0     # number of iterations\n",
    "    for k in range(500):\n",
    "        cnt += 1\n",
    "        xOld, fOld = x, fx\n",
    "        x  += alpha * gradF(x)\n",
    "        fx  = f(x)        \n",
    "        if fx <= fOld:    # f didn't increased, learning rate is too high\n",
    "            alpha *= 0.5  # decrease the learning rate\n",
    "            x, fx = xOld, fOld    # reset x\n",
    "            continue\n",
    "        else:             # f has increased\n",
    "            alpha *= 1.2  # increase the learning rate\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start   = np.array([0.0, 0.0])\n",
    "eps     = 10 ** -5\n",
    "gamma, beta = findMaximum(ll, gradLL, start, eps)\n",
    "print(f'model: P(pass|hours) = S({beta} + {gamma} * hours)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this function together with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.set_style('whitegrid')\n",
    "plt.title('Pass/Fail vs. Hours of Study')\n",
    "H = np.arange(0.0, 6.0, 0.05)\n",
    "P = sigmoid(beta + gamma * H)\n",
    "sns.lineplot(x=H, y=P, color='r')\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.xlabel('Hours of Study')\n",
    "plt.ylabel('Probability of Passing the Exam')\n",
    "plt.xticks(np.arange(0.0, 6.0, step=0.5))\n",
    "plt.yticks(np.arange(-0.0, 1.01, step=0.1))\n",
    "plt.scatter(x, (y + 1) / 2, color='b')\n",
    "plt.savefig('exam-probability.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
