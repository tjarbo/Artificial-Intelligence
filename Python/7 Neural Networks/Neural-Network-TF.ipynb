{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow        as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following magic command is necessary to prevent the Python kernel to die because of linkage problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env KMP_DUPLICATE_LIB_OK=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{vectorized_result}(d)$ converts the digit $d \\in \\{0,\\cdots,9\\}$ and returns a NumPy vector $\\mathbf{x}$ of shape $(10, 1)$ such that\n",
    "$$\n",
    "\\mathbf{x}[i] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "     1 & \\mbox{if $i = j$;} \\\\\n",
    "     0 & \\mbox{otherwise.}\n",
    "  \\end{array}  \n",
    "\\right.\n",
    "$$\n",
    "This function is used to convert a digit $d$ into the expected output of a neural network that has an output unit for every digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(d):\n",
    "    e    = np.zeros((10, ), dtype=np.float32)\n",
    "    e[d] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we are using is stored as a <a href=\"https://docs.python.org/3/library/gzip.html\">gzipped</a>, \n",
    "<a href=\"https://docs.python.org/3/library/pickle.html\">pickled</a> file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{load_data}()$ returns a pair of the form\n",
    "$$ (\\texttt{training_data}, \\texttt{test_data}) $$\n",
    "where \n",
    "- $\\texttt{training_data}$ is a list containing $50,000$ pairs $(\\textbf{x}, \\textbf{y})$ s.t. $\\textbf{x}$ is a \n",
    "  784-dimensional `numpy.ndarray` containing the input image and $\\textbf{y}$ is a 10-dimensional `numpy.ndarray`   \n",
    "  corresponding to the correct digit for x.\n",
    "- $\\texttt{test_data}$ is a list containing $10,000$ pairs $(\\textbf{x}, \\textbf{y})$.  In each case, \n",
    "  $\\textbf{x}$ is a 784-dimensional `numpy.ndarry` containing the input image\n",
    "  and $\\textbf{y}$ is a 10-dimensional `numpy.ndarray` corresponding to the correct digit for $\\textbf{x}$.\n",
    "  \n",
    "We do not use the validation data that are provided in the file `mnist.pkl.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('../mnist.pkl.gz', 'rb') as f:\n",
    "        train, validate, test = pickle.load(f, encoding=\"latin1\")\n",
    "    X_train = np.array([np.reshape(x, (784, )) for x in train[0]])\n",
    "    X_test  = np.array([np.reshape(x, (784, )) for x in test [0]])\n",
    "    Y_train = np.array([vectorized_result(y) for y in train[1]])\n",
    "    Y_test  = np.array([vectorized_result(y) for y in test [1]])\n",
    "    return X_train.T, X_test.T, Y_train.T, Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{show_digit}(\\texttt{row}, \\texttt{columns}, \\texttt{offset})$ \n",
    "shows $\\texttt{row} \\cdot \\texttt{columns}$ images of the training data.  The first image shown is the image at index $\\texttt{offset}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digits(rows, columns, offset=0):\n",
    "    f, axarr = plt.subplots(rows, columns)\n",
    "    for r in range(rows):\n",
    "        for c in range(columns):\n",
    "            i     = r * columns + c + offset\n",
    "            image = 1 - X_train[:,i]\n",
    "            image = np.reshape(image, (28, 28))\n",
    "            axarr[r, c].imshow(image, cmap=\"gray\")\n",
    "            axarr[r, c].axis('off')\n",
    "    plt.savefig(\"digits.pdf\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_digits(3, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create placeholders to use for the data.  Below, `None` stands for the yet unknown number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "X = tf.compat.v1.placeholder(tf.float32, [784, None]) # mnist data images of shape (28*28=784, ?)\n",
    "Y = tf.compat.v1.placeholder(tf.float32, [ 10, None]) # 0-9 digits recognition => 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the <em style=\"color:blue;\">weight matrices</em> and <em style=\"color:blue;\">biases</em> for a neural net that is \n",
    "able to recognize the digits shown in these images.  We initialize these weight matrices randomly. The function $\\texttt{rndMatrix}(\\texttt{rows}, \\texttt{cols})$ returns a matrix of shape $(\\texttt{rows}, \\texttt{cols})$ that is filled with random numbers that have a Gaussian distribution with mean $0$ and variance $\\displaystyle\\frac{1}{\\texttt{rows}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndMatrix(rows, cols):\n",
    "    return tf.compat.v1.truncated_normal((rows, cols), 0.0, 1 / np.sqrt(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the <em style=\"color:blue;\">topology</em> of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize  = 28 * 28\n",
    "hiddenSize = 60\n",
    "outputSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasesH  = tf.Variable(tf.zeros((hiddenSize, 1)        )) # biases hidden layer  \n",
    "biasesO  = tf.Variable(tf.zeros((outputSize, 1)        )) # biases output layer \n",
    "weightsH = tf.Variable(rndMatrix(hiddenSize, inputSize )) # weights hidden layer\n",
    "weightsO = tf.Variable(rndMatrix(outputSize, hiddenSize)) # weights output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AH     = tf.sigmoid(weightsH @  X + biasesH) # activation hidden layer\n",
    "Y_pred = tf.sigmoid(weightsO @ AH + biasesO) # activation output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the mean squared error as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.losses.mean_squared_error(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some variables and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α         =  15\n",
    "epochs    =  60\n",
    "mbs       = 100             # mini batch size\n",
    "n_test    = X_test.shape[1]\n",
    "n         = X_train.shape[1]\n",
    "n_batches = int(n / mbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use <em style=\"color:blue;\">gradient descent</em> to minimize this cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(α).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{next_batch}(s)$ returns the next batch of the given size.  It returns a pair of the form $(X, Y)$ where $X$ is a matrix of shape\n",
    "$(784, s)$ and $Y$ is a matrix of shape $(10, s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(size):\n",
    "    global count\n",
    "    X_batch  = X_train[:, count:count+size]\n",
    "    Y_batch  = Y_train[:, count:count+size]\n",
    "    count   += size\n",
    "    return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.compat.v1.set_random_seed(42)\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "with tf.compat.v1.Session() as tfs:\n",
    "    tfs.run(init)\n",
    "    for j in range(epochs):\n",
    "        count    = 0\n",
    "        avg_cost = 0.0\n",
    "        for i in range(n_batches):\n",
    "            X_batch, Y_batch = next_batch(mbs)\n",
    "            _, c = tfs.run([optimizer, cost], {X: X_batch, Y: Y_batch})\n",
    "            avg_cost += c / n_batches\n",
    "        correct = tfs.run(tf.equal(tf.argmax(Y_pred, 0), tf.argmax(Y, 0)), {X: X_test, Y: Y_test})\n",
    "        print('Epoch: %2d, accuracy: %.4f, cost %.5f' % (j, np.sum(correct) / len(correct), avg_cost))\n",
    "    print(\"Optimization Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
