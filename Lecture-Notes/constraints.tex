\chapter{Solving Constraint Satisfaction Problems}
In this chapter we discuss various algorithms for solving 
\href{https://en.wikipedia.org/wiki/Constraint_satisfaction_problem}{constraint satisfaction problems}.
In a \blue{constraint satisfaction problem} we are given a set of \blue{formulas} and search for \blue{values}
that can be 
assigned to the \blue{variables} occurring in these formulas so that all of the formulas evaluate as true.
Constraint satisfaction problems can be seen as a refinement of the search problems discussed in the previous
chapter:  In a search problem, the states are abstract and therefore have no structure that can be exploited to
guide the search, while in a \blue{constraint satisfaction problem}, the states have a structure, as these
states are \blue{variable assignments}.  This structure can be exploited to guide the search.  This chapter is
structured as follows: 
\begin{enumerate}[(a)]
\item The first section defines the notion of a constraint satisfaction problem.  In order to illustrate this
      notion, we present two examples: \blue{map colouring} and the \blue{eight queens puzzle}.  After that, we discuss
      applications of constraint satisfaction problems. 
\item The simplest algorithm to solve a constraint satisfaction problem is via \blue{brute force search}.
      The idea behind \emph{brute force search} is to test all possible \blue{variable assignments}.
\item In most cases, the search space is so large that it is not feasible to enumerate all variable assignments.
      \blue{Backtracking search} improves on brute force search by mixing the generation
      of variable assignments with the testing of the constraints.  In many cases, this approach
      improves the performance of the brute search algorithm drastically.
\item Backtracking search can be refined by using both \blue{constraint propagation} and 
      the \blue{most restricted variable} heuristic.
\item Furthermore, checking the \blue{consistency} of the values assigned to different variables
      can reduce the size of the search space considerably. 
\item Finally, \blue{local search} is a completely different approach to solve
      constraint satisfaction problems.  This approach is especially useful if the constraint satisfaction
      problem is huge, but not complicated.
\end{enumerate}
When we have finished our discussion of constraint satisfaction problems, we will have implemented a
\blue{constraint solver} that is able to solve instances of the most difficult
\href{https://en.wikipedia.org/wiki/Sudoku}{Sudoku} puzzles in seconds.

\section[Formal Definition of \textsc{Csp}s]{Formal Definition of Constraint Satisfaction Problems}
Formally, we define a 
\href{https://en.wikipedia.org/wiki/Constraint_satisfaction_problem}{constraint satisfaction problem} as a triple
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{P} := \langle \texttt{Vars}, \texttt{Values}, \texttt{Constraints} \rangle$
\\[0.2cm]
where \index{constraint satisfaction problem}
\begin{enumerate}[(a)]
\item $\texttt{Vars}$ is a set of strings which serve as \blue{variables},
\item $\texttt{Values}$ is a set of \blue{values} that can be assigned to the variables in $\texttt{Vars}$.
\item $\texttt{Constraints}$ is a set of formulas from \blue{first order logic}.  Each of these formulas is
      called a \blue{constraint} of $\mathcal{P}$.

      In order to be able to interpret these formulas, we need a \blue{first order structure} $\mathcal{S} = \langle \mathcal{U}, \mathcal{J} \rangle$.  
      Here, $\mathcal{U}$ is the \blue{universe} of $\mathcal{S}$ and we will assume that this
      universe is identical to the set $\texttt{Values}$, that is we have
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathcal{U} = \texttt{Values}$.
      \\[0.2cm]
      The second component $\mathcal{J}$ defines the
      \blue{interpretations} of the function symbols and predicate symbols that are used in the formulas\
      defining the constraints.  In the following we assume that these interpretations are understood from the
      context of the constraint satisfaction problem $\mathcal{P}$ and hence need not be specified explicitly.
      Later, when we discuss examples of constraint 
      satisfaction problems, both the function symbols and the predicate symbols will be interpreted
      by functions written in \textsl{Python}.
\end{enumerate}
In the following, the abbreviation \blue{\ac{csp}} is short for \blue{constraint satisfaction problem}.
Given a \ac{csp}
\\[0.2cm]
\hspace*{1.3cm}
 $\mathcal{P} = \langle \texttt{Vars}, \texttt{Values}, \texttt{Constraints} \rangle$, 
\\[0.2cm]
a \blue{variable assignment} for $\mathcal{P}$ is a function \index{variable assignment}
\\[0.2cm]
\hspace*{1.3cm}
$A: \texttt{Vars} \rightarrow \texttt{Values}$
\\[0.2cm]
that maps variables to values.  A variable assignment $A$ is a \blue{solution} \index{solution of a \ac{csp}}
of the \ac{csp} $\mathcal{P}$  
if, given the assignment $A$, all constraints of $\mathcal{P}$ are satisfied, i.e.~we have
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{eval}(f, A) = \texttt{true}$ \quad for all $f \in \texttt{Constraints}$.
\\[0.2cm]
Finally, a \blue{partial variable assignment} $B$ for $\mathcal{P}$ is a function \index{partial variable assignment}
\\[0.2cm]
\hspace*{1.3cm}
$B: \texttt{Vars} \rightarrow \texttt{Values} \cup \{ \Omega \}$ \quad where $\Omega$ denotes the undefined value.
\\[0.2cm]
Hence, a partial variable assignment does not assign values to all variables.  Instead, it assigns values only
to a subset of the set $\texttt{Vars}$.  The \blue{domain} $\texttt{dom}(B)$ of a partial variable assignment $B$ is the
set of those variables that are assigned a value different from $\Omega$, i.e.~we define
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{dom}(B) := \bigl\{ x \in \texttt{Vars} \mid B(x) \not= \Omega \bigr\}$.
\\[0.2cm]
We illustrate the definitions given so far by presenting two examples.


\begin{figure}[!ht]
  \centering
  \framebox{\epsfig{file=Figures/australia.pdf,scale=0.8}} 
  \caption{A map of Australia.}
  \label{fig:australia.pdf}
\end{figure}

\subsection{Example: Map Colouring}
\index{map coloring}
In \href{https://en.wikipedia.org/wiki/Four_color_theorem}{map colouring} a map showing different states and their
borders is given and the task is to colour the different states such that no two states that have a common
border share the same colour.  \myFig{australia.pdf} shows a map of
\href{https://en.wikipedia.org/wiki/Australia}{Australia}.  There are seven different 
states in Australia:
\begin{enumerate}
\item \href{https://en.wikipedia.org/wiki/Western_Australia}{Western Australia}, abbreviated as $\mathrm{WA}$,
\item \href{https://en.wikipedia.org/wiki/Northern_Territory}{Northern Territory}, abbreviated as $\mathrm{NT}$,
\item \href{https://en.wikipedia.org/wiki/South_Australia}{South Australia}, abbreviated as $\mathrm{SA}$,
\item \href{https://en.wikipedia.org/wiki/Queensland}{Queensland}, abbreviated as $\mathrm{Q}$,
\item \href{https://en.wikipedia.org/wiki/New_South_Wales}{New South Wales}, abbreviated as $\mathrm{NSW}$,
\item \href{https://en.wikipedia.org/wiki/Victoria_(Australia)}{Victoria}, abbreviated as $\mathrm{V}$, and
\item \href{https://en.wikipedia.org/wiki/Tasmania}{Tasmania}, abbreviated as $\mathrm{T}$.
\end{enumerate}
Figure \ref{fig:australia.pdf} would certainly look better if different states that share a common border had
been coloured with different colours.  For the purpose of 
this example let us assume that we only have the three colours \red{red}, \green{green}, and \blue{blue}
available.  The task is then to colour the different 
states in a way that no two neighbouring states share the same colour.  This task can be formalized as a
constraint satisfaction problem.  To this end we define: 
\begin{enumerate}
\item $\texttt{Vars} := \{ \mathrm{WA}, \mathrm{NT}, \mathrm{SA}, \mathrm{Q}, \mathrm{NSW}, \mathrm{V}, \mathrm{T} \}$,
\item $\texttt{Values} := \{ \texttt{\red{red}}, \texttt{\green{green}}, \texttt{\blue{blue}} \}$,
\item $\texttt{Constraints} := $ \\[0.2cm]
      \hspace*{0.8cm}
      $\bigl\{ \texttt{WA} \not= \texttt{NT},\, \texttt{WA} \not= \texttt{SA},\, \texttt{SA} \not= \texttt{Q},\, 
                \texttt{NT} \not= \texttt{Q},\,
                \texttt{SA} \not= \texttt{Q},\, \texttt{SA} \not= \texttt{NSW},\, \texttt{SA} \not= \texttt{V},\,
                \texttt{Q} \not= \texttt{NSW},\, \texttt{NSW} \not= \texttt{V},\, \texttt{V} \not= \texttt{T}
       \bigr\}$.
\end{enumerate}
Then $\mathcal{P} := \langle \texttt{Vars},\, \texttt{Values},\, \texttt{Constraints} \rangle$ is a constraint satisfaction problem.  
If we define the assignment $A$ such that
\begin{enumerate}[(a)]
\item $A(\mathrm{WA}) = \texttt{\blue{blue}}$,
\item $A(\mathrm{NT}) = \texttt{\red{red}}$,
\item $A(\mathrm{SA}) = \texttt{\green{green}}$,
\item $A(\mathrm{Q}) = \texttt{\blue{blue}}$,
\item $A(\mathrm{NSW}) = \texttt{\red{red}}$,
\item $A(\mathrm{V}) = \texttt{\blue{blue}}$,
\item $A(\mathrm{T}) = \texttt{\red{red}}$,
\end{enumerate}
then it is straightforward to check that this assignment is indeed a solution to the constraint satisfaction problem $\mathcal{P}$.

\subsection{Example: The Eight Queens Puzzle}
\index{eight queens puzzle}
The \href{https://en.wikipedia.org/wiki/Eight_queens_puzzle}{eight queens puzzle} asks to put 8 queens on a
chessboard such that no queen can attack another queen.  In \href{https://en.wikipedia.org/wiki/Chess}{chess},
a queen can attack all pieces that are either in the same row, the same column, or the same diagonal.  If we
want to put 8 queens on a chessboard such that no two queens can attack each other, we have to put exactly one
queen in every row:  If we would put more than one queen in a row, the queens in that row could attack each
other.  If we would leave a row empty, then, given that the other rows contain at most one queen, there would
be less than 8 queens on the board.  Therefore, in order to model the eight queens problem as a constraint
satisfaction problem, we will use the following set of variables:  \index{8 queens puzzle}
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Vars} := \{ \texttt{V}_1, \texttt{V}_2, \texttt{V}_3, \texttt{V}_4, \texttt{V}_5, \texttt{V}_6, \texttt{V}_7,\texttt{V}_8 \}$,
\\[0.2cm]
where for $i \in \{1,\cdots,8\}$ the variable $\texttt{V}_i$ specifies the column of the queen that is placed in
row $i$.   As the column numbers run from $1$ up to $8$, we define the set $\texttt{Values}$ as
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Values} := \{1,2,3,4,5,6,7,8\}$.
\\[0.2cm]
Next, let us define the constraints.  There are two different types of constraints.
\begin{enumerate}
\item We need constraints that express that no two queens that are positioned in different rows share the same
      column.  To capture these constraints, we define
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{DifferentCol} := \bigl\{ \texttt{V}_i \not= \texttt{V}_j \bigm| i \in \{1,\cdots,8\} \wedge j \in \{1,\cdots,8\} \wedge j < i \bigr\}$.
      \\[0.2cm]
      Here the condition $j < i$ ensures that, for example,  while we have the constraint
      $\texttt{V}_2 \not=
      \texttt{V}_1$ we do not also have the constraint  $\texttt{V}_1 \not= \texttt{V}_2$, as the latter 
      constraint would be redundant if the former constraint had already been established.
\item We need constraints that express that no two queens positioned in different rows share the same 
      diagonal.  The queens in row $i$ and row $j$ share the same diagonal iff the equation
      \\[0.2cm]
      \hspace*{1.3cm}
      $|i - j| = |V_i - V_j|$
      \\[0.2cm]
      holds.  The expression $|i-j|$ is the absolute value of the difference of the rows of the queens in row
      $i$ and row $j$,  while the expression $|V_i - V_j|$ is the absolute value of the difference of the
      columns of these queens.  To capture these constraints, we define
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{DifferentDiag} := \bigl\{ |i  - j| \not= |\texttt{V}_i - \texttt{V}_j| \bigm| i \in \{1,\cdots,8\} \wedge j \in \{1,\cdots,8\} \wedge j < i \bigr\}$.
      \\[0.2cm]
      For a fixed pair of values $\langle j, V_j\rangle$ the equations
      \\[0.2cm]
      \hspace*{1.3cm}
      $V_i = V_j - j + i $ \quad and \quad $V_i = V_j + j - i$
      \\[0.2cm] 
      are the linear equations for the straight lines with slope $1$ and $-1$ that pass through
      $\langle j, V_i \rangle$.
\end{enumerate}
Then, the set of constraints is defined as 
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Constraints} := \texttt{DifferentCol} \cup \texttt{DifferentDiag}$
\\[0.2cm]
and the eight queens problem can be stated as the constraint satisfaction problem
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{P} := \langle \texttt{Vars}, \texttt{Values}, \texttt{Constraints} \rangle$.
\\[0.2cm]
If we define the assignment $A$ such that
\\[0.2cm]
\hspace*{1.3cm}
$A(V_1) := 4,\; A(V_2) := 8,\; A(V_3) := 1,\; A(V_4) := 2,\; A(V_5) := 6,\; A(V_6) := 2$,
\\[0.2cm]
\hspace*{1.3cm}
$A(V_7) := 7,\; A(V_8) := 5$,
\\[0.2cm]
then it is easy to see that this assignment is a solution of the eight queens problem.  This solution is shown
in \myFig{eight-queens.txt}.  In this figure, we have numbered the rows from top to bottom, i.e.~the topmost
row is row number $1$ and therefore the column of the queen in the first is determined by the variable $V_1$.


\begin{figure}[!ht]
  \centering
\hspace*{0.0cm}
\vbox{\offinterlineskip
   \hrule height1pt
   \hbox{\vrule width1pt\bigchess
         \vbox{\hbox{0Z0L0Z0Z}
               \hbox{Z0Z0Z0ZQ}
               \hbox{QZ0Z0Z0Z}
               \hbox{Z0L0Z0Z0}
               \hbox{0Z0Z0L0Z}
               \hbox{ZQZ0Z0Z0}
               \hbox{0Z0Z0ZQZ}
               \hbox{Z0Z0L0Z0}}%
         \vrule width1pt}
   \hrule height1pt}

  \caption{A solution of the eight queens problem.}
  \label{fig:eight-queens.txt}
\end{figure}
Later, when we develop algorithms to solve  \ac{csp}s, we will represent variable assignments and partial
variable assignments as \textsl{Python} \blue{dictionaries}.  For example, $A$ would then be represented as the
dictionary 
\\[0.2cm]
\hspace*{1.3cm}
$A := \bigl\{ \mathrm{V}_1:4, \mathrm{V}_2:8, \mathrm{V}_3:1, \mathrm{V}_4:2, 
             \mathrm{V}_5:6, \mathrm{V}_6:2, \mathrm{V}_7:7, \mathrm{V}_8:5 
      \bigr\}$.
\\[0.2cm]
If we define 
\\[0.2cm]
\hspace*{1.3cm}
$B := \bigl\{ \mathrm{V}_1:4, \mathrm{V}_2:8, \mathrm{V}_3:1 \bigr\}$,
\\[0.2cm]
then $B$ is a \blue{partial} variable assignment and $\texttt{dom}(B) = \{ \mathrm{V}_1, \mathrm{V}_2, \mathrm{V}_3 \}$.  This
partial variable assignment is shown in \myFig{eight-queens-partial.txt}.

\begin{figure}[!ht]
  \centering
\hspace*{0.0cm}
\vbox{\offinterlineskip
   \hrule height1pt
   \hbox{\vrule width1pt\bigchess
         \vbox{\hbox{0Z0L0Z0Z}
               \hbox{Z0Z0Z0ZQ}
               \hbox{QZ0Z0Z0Z}
               \hbox{Z0Z0Z0Z0}
               \hbox{0Z0Z0Z0Z}
               \hbox{Z0Z0Z0Z0}
               \hbox{0Z0Z0Z0Z}
               \hbox{Z0Z0Z0Z0}}%
         \vrule width1pt}
   \hrule height1pt}

  \caption{The partial assignment $\bigl\{ \mathrm{V}_1:4, \mathrm{V}_2:8, \mathrm{V}_3:1 \bigr\}$.}
  \label{fig:eight-queens-partial.txt}
\end{figure}



\myFig{N-Queens-Problem-CSP.ipynb} shows a \textsl{Python} program that can be used to create a \ac{csp} that
encodes the eight queens puzzle.  The code shown in this figure is more general than necessary.  Given a natural
number $n$, the function call $\texttt{create\_csp}(n)$ creates a constraint satisfaction problem $\mathcal{P}$ that generalizes
the eight queens problem to the problem of placing $n$ queens on a board of size $n$ times $n$ such that no
queen can capture another queen.  The fact that the n-queen problem is parameterized by the number of queens n
gives us the ability to check how the running time of the algorithms for solving \ac{csp}s scales with the size
of the problem. 


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.8cm,
                xrightmargin  = 0.cm,
              ]{python3}    
    def create_csp(n):
        S            = range(1, n+1)           
        Variables    = { f'V{i}' for i in S }
        Values       = set(S)
        SameRow      = { f'V{i} != V{j}' for i in S
                                         for j in S
                                         if  i < j 
                       }
        SameDiagonal = { f'abs(V{j} - V{i}) != {j - i}' for i in S
                                                        for j in S 
                                                        if  i < j 
                       }
        return (Variables, Values, SameRow | SameDiagonal)
\end{minted}
\vspace*{-0.3cm}
\caption{The $n$ queens problem formulated as a \ac{csp}.}
\label{fig:N-Queens-Problem-CSP.ipynb}
\end{figure}


The beauty of \href{https://en.wikipedia.org/wiki/Constraint_programming}{constraint programming} is the fact
that we will be able to develop a so called \blue{constraint solver} that takes as input a \ac{csp}
like the one produced by the program shown in Figure \ref{fig:N-Queens-Problem-CSP.ipynb} and that is capable of
computing a solution automatically.  In effect, this enables us to use
\href{https://en.wikipedia.org/wiki/Declarative_programming}{declarative programming}:  Instead of developing
an algorithm that solves a given problem we confine ourselves to  specifying the problem precisely and then let a
general purpose problem solver do the job of computing the solution.  This approach of declarative programming 
was one of the main ideas incorporated in the programming language
\href{https://en.wikipedia.org/wiki/Prolog}{Prolog}.  While \blue{Prolog} could not live up to its promisses
as a viable general purpose programming language, constraint programming has proved to be very useful in a
number of domains.  

\subsection{Applications}
Besides the toy problems discussed so far, there are a number of industrial applications of constraint
satisfaction problems.  The most important application seem to be variants of
\href{https://en.wikipedia.org/wiki/Scheduling_(production_processes)}{scheduling problems}. 
A simple example of a scheduling problem is the problem of generating a time table for a school.  A school has
various teachers, each of which can teach some subjects but not others.  Furthermore, there are a number of
classes that must be taught in different subjects.  The problem is then to assign teachers to classes and to
create a time table.  A special case of sheduling problems is
\href{https://en.wikipedia.org/wiki/Crew_scheduling}{crew scheduling}.  For example, airlines have to solve a
crew scheduling problem in order to efficiently assign crews of pilots and crews of stewards to their
aircrafts.  Stewards and pilots work in different crews as they have different required resting times.

\section{Brute Force Search}
The most straightforward algorithm to solve a \ac{csp} is to test all possible combinations of assigning
values to variables.  If there are $n$ different values that can be assigned to $k$ variables, this amounts to 
checking $n^k$ different assignments.  For example, for the eight queens problem there are 8 variables and
8 possible values leading to 
\\[0.2cm]
\hspace*{1.3cm}
$8^8 = 2^{24} = 16,777,216$
\\[0.2cm]
different assignments that need to be tested.  Given the clock rate of modern computers, checking a million
assignments per second is plausible.  Hence, this approach is able to solve the eight queens problem in
about 30 seconds.  The approach of testing all possible combinations is known as
\href{https://en.wikipedia.org/wiki/Brute-force_search}{brute force search}.  \index{brute force search}
An implementation of brute force search is shown in \myFig{Brute-Force-Solver.ipynb}. 

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def solve(P):
        return brute_force_search({}, P)

    def brute_force_search(Assignment, csp):
        Variables, Values, Constraints = csp
        if len(Assignment) == len(Variables): # all variables have been assigned
            if check_all_constraints(Assignment, Constraints):
                print('Assignment:', Assignment)
                return Assignment
            else:
                return None
        var = arb(Variables - set(Assignment.keys()))
        for value in Values:
            NewAss = Assignment.copy()
            NewAss[var] = value
            result = brute_force_search(NewAss, csp)
            if result != None:
                return result
        return None
\end{minted}
\vspace*{-0.3cm}
\caption{Solving a \ac{csp} via brute force search.}
\label{fig:Brute-Force-Solver.ipynb}
\end{figure}

The function $\texttt{solve}$ takes a constraint satisfaction problem $P$ as its input.  
This $\texttt{CSP}$ is given as a triple of the form  
\\[0.2cm]
\hspace*{1.3cm}
$P = (\texttt{Variables}, \texttt{Values}, \texttt{Constraints})$.
\\[0.2cm]
The sole purpose of the function \texttt{solve} is to call the function \texttt{brute\_force\_search}, which
needs an additional argument.  This argument is a \blue{partial variable assignment} that is initially empty.  Every
recursive iteration of the function \texttt{brute\_force\_search} assigns one additional variable. 
\begin{enumerate}
\item $\texttt{Assignment}$ is a partial variable assignment.  Initially, this assignment will be the
      empty dictionary.  Every recursive call of $\texttt{brute\_force\_search}$ adds the assignment of one variable to
      the given assignment. 
\item $\texttt{csp}$ is a triple of the form
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{csp} = (\texttt{Variables}, \texttt{Values}, \texttt{Constraints})$.
      \\[0.2cm]
      Here, \texttt{Constraints} is a set of Boolean expressions that are given as strings.  These
      strings have to follow the syntax of \textsl{Python} so that they can be evaluated using the
      \textsl{Python} function $\texttt{eval}$.
\end{enumerate}
The implementation of $\texttt{brute\_force\_search}$ works as follows:
\begin{enumerate}
\item If all variables have been assigned a value, the dictionary $\texttt{Assignment}$ will have the same
      number of entries as the set $\texttt{Variables}$ has elements.  Hence, in that case
      $\texttt{Assignment}$ is a complete assignment of all variables and we now have to test whether
      all constraints are satisfied.  This is done using the auxiliary function
      $\texttt{check\_all\_constraints}$ that is shown in \myFig{Brute-Force-Solver.ipynb-2}. 
      If the current $\texttt{Assignment}$ does indeed satisfy all constraints, it is a solution to the given
      \ac{csp} and is therefore returned.

      If, instead, some constraint is violated, then $\texttt{brute\_force\_search}$ returns the value
      \texttt{None}.
\item If the assignment is not yet complete, we arbitrarily 
      pick a variable $\texttt{var}$ from the set of those $\texttt{Variables}$ that still have no value assigned.  
      Then, for every possible  $\texttt{value}$ in the set $\texttt{Values}$, we extend the current partial
      $\texttt{Assignment}$ to a new assignment \texttt{NewAss} that satisfies
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{NewAss[var] = value}.
      \\[0.2cm]
      Next, the algorithm recursively tries to find a solution for this new partial assignment.
      If this recursive call succeeds, the solution it has computed is returned.  Otherwise, the next value
      for the given variable \texttt{var} is tried.
\item If none of the values work for \texttt{var}, the function returns \texttt{None}.
\end{enumerate}


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = last,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.8cm,
                xrightmargin  = 0.8cm,
              ]{python3}
    def check_all_constraints(Assignment, Constraints):
        A = Assignment.copy()
        return all(eval(f, A) for f in Constraints)
\end{minted}
\vspace*{-0.3cm}
\caption{Auxiliary functions for brute force search.}
\label{fig:Brute-Force-Solver.ipynb-2}
\end{figure}

The function $\texttt{check\_all\_constraints}$ takes a complete variable $\texttt{Assignment}$ as
its first input.  The second input is the set $\texttt{Constraints}$ which is a set of \textsl{Python}
expressions.  For all expressions
$\texttt{f}$ from the set $\texttt{Constraints}$, the function $\texttt{check\_all\_constraints}$ checks
whether $\texttt{f}$ yields \texttt{True} under the given variable assignment.
This check is done using the function $\texttt{eval}$, which is a predefined function.  
This function takes two arguments: 
\begin{enumerate}[(a)]
\item The first argument is a \textsl{Python} expression \texttt{f}.
\item The second argument is a variable assignment \texttt{A}, that is represented as a dictionary.
\end{enumerate}
The function \texttt{eval} evaluates the expression \texttt{f}.  In order to do this, any variables occurring
in \texttt{f} are assigned values according to the variable assignment \texttt{A}.  As a side effect, the function
\texttt{eval} changes the dictionary \texttt{A} that is used as its second argument.  This is the reason we have
to make a copy of the \texttt{Assignment} that is given as the first argument of the function
\texttt{check\_all\_constraints}. 

When I tested the program discussed above with the eight queens problem, it took about 30 seconds to
compute a solution.  In contrast, the seven queens problem took about 1.7 second.  As we have
\\[0.2cm]
\hspace*{1.3cm}
$\ds\frac{8^8}{7^7} \approx 20$ \quad and \quad $30 / 1.7 \approx 18$ 
\\[0.2cm]
this shows that the computation time does indeed roughly grow with the number of possible assignments that
have to be checked.  However, the correspondence is not exact.  The reason is that we stop our
search as soon as a solution is found.  If we are lucky and the given \ac{csp} is easy to solve, this
might happen when we have checked only a small portion of the set of all possible assignments.

\section{Backtracking Search}
For the $n$ queens problem the number of possible variable assignments growth as fast as $n^n$.
This growth is super-exponential and this is what usually happens when we scale a \ac{csp} up. 
The reason is that the number of all variable assignments is given as
\\[0.2cm]
\hspace*{1.3cm}
$\mathrm{card}(\texttt{Values})^{\mathrm{card}(\texttt{Vars})}$,
\\[0.2cm]
where for a set $M$, the expression $\mathrm{card}(M)$ returns the number of elements of $M$.
For this reason, \blue{brute force search} is only viable for small problems.  One approach to solve a \ac{csp}
that is both conceptually simple and at least more efficient than brute force search is \blue{backtracking}.  The idea
is to try to evaluate constraints as soon as possible:  If $C$ is a constraint and $B$ is a partial assignment
such that all the variables occurring in $C$ have already been assigned a value in $B$ and the evaluation of $C$
fails, then there is no point in trying to complete the variable assignment $B$.  Hence, in backtracking we
evaluate a constraint $C$ as soon as all of its variables have been assigned a value.  If $C$ is not valid, we
discard the current partial variable assignment.  This approach can result in huge time savings
when compared to the baseline of brute force search.

\myFig{Backtrack-Solver.ipynb} shows a simple \ac{csp} solver 
that employs the backtracking strategy.  \index{backtracking}
We discuss this program next.  The function $\texttt{solve}$ takes a constraint
satisfaction problem $\texttt{P}$ as input and tries to find a solution.  


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def solve(P):
        Variables, Values, Constraints = P
        csp = (Variables, Values, [(f, collect_variables(f)) for f in Constraints])
        try:
            return backtrack_search({}, csp)
        except Backtrack:
            return None
\end{minted}
\vspace*{-0.3cm}
\caption{A backtracking \ac{csp} solver.}
\label{fig:Backtrack-Solver.ipynb}
\end{figure}

\begin{enumerate}
\item First, the \ac{csp} \texttt{P} is split into its components.
\item Next, for every constraint $\texttt{f}$ of the given \ac{csp}, we compute the set of variables that
      are used in $\texttt{f}$.  This is done using the function $\texttt{collect\_variables}$ that is shown in
      Figure \ref{fig:collect_variables.py} on page \pageref{fig:collect_variables.py}.
      These variables are then stored together with the constraint $\texttt{f}$ and
      the correspondingly modified data structure is stored in the variable \texttt{csp} and is called an
      \blue{augmented \ac{csp}}.

      The reason to compute and store these variables is efficiency: When we later check whether a constraint $\texttt{f}$
      is satisfied for a partial variable assignment $\texttt{Assignment}$ where $\texttt{Assignment}$ is
      stored as a dictionary, we only need to check the constraint $\texttt{f}$ iff all of the variables occurring
      in $\texttt{f}$ are elements of the domain of $\texttt{Assignment}$.   It would be wasteful to compute
      these variables every time that a partial variable assignment is extended.
\item Next, we call the function $\texttt{backtrack\_search}$ to compute a solution of $\texttt{CSP}$.
      This function is enclosed in a \texttt{try}-\texttt{except}-block that catches exceptions of class
      \texttt{Backtrack}.  This class is defined as follows:
      
\begin{verbatim}
      class Backtrack(Exception):
          pass
\end{verbatim}
      Its only purpose is to create a name for the special kind of exceptions used to administer backtracking.
      The reason for enclosing the call to \texttt{backtrack\_search} in a \texttt{try}-\texttt{except}-block
      is that the function $\texttt{backtrack\_search}$ either returns a solution or, if it is not
      able to find a solution, it raises an exception of class \texttt{Backtrack}.
      The \texttt{try}-\texttt{except}-block ensures that this exception is silently discarded.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def backtrack_search(Assignment, P):
        Variables, Values, Constraints = P
        if len(Assignment) == len(Variables):
            return Assignment
        var = arb(Variables - set(Assignment.keys()))
        for value in Values:
            try:
                if is_consistent(var, value, Assignment, Constraints):
                    NewAss = Assignment.copy()
                    NewAss[var] = value
                    return backtrack_search(NewAss, P)
            except Backtrack:
                continue
        raise Backtrack()  
\end{minted}
\vspace*{-0.3cm}
\caption{A backtracking \ac{csp} solver: The function \texttt{backtrack\_search}.}
\label{fig:Backtrack-Solver.ipynb:backtrack_search}
\end{figure}

Next, we discuss the implementation of the function $\texttt{backtrack\_search}$  that is shown in
\myFig{Backtrack-Solver.ipynb:backtrack_search}.  This function receives a partial assignment
$\texttt{Assignment}$ as input together with an augmented \ac{csp} \texttt{P}.  This partial assignment is
\blue{consistent} with $\texttt{P}$:  If $\texttt{f}$ is a constraint of $\texttt{CSP}$ such that
all the variables occurring in $\texttt{f}$ are members of $\texttt{dom}(\texttt{Assignment})$, then evaluating
$\texttt{f}$ using $\texttt{Assignment}$ yields $\texttt{true}$.  Initially, this partial assignment is empty
and hence trivially consistent.  The idea is to extend this partial assignment until it is a complete variable 
assignment.  We take care to ensure that this partial variable assignment remains consistent when it is
extended.  This way, once this assignment is complete it has to satisfy all the constraints of the given $\texttt{CSP}$.
\begin{enumerate}
\item First, the augmented \ac{csp} \texttt{P} is split into its components.
\item Next, if $\texttt{Assignment}$ is already a complete variable assignment, i.e.~if the dictionary
      $\texttt{Assignment}$ has as many elements as there are variables, then it must be a solution of
      the $\texttt{CSP}$ and, therefore, it is returned.  The reason is that the function
      \texttt{backtrack\_search} is only called with a \blue{consistent} partial assignment.
\item Otherwise, we have to extend the partial $\texttt{Assignment}$.  In order to do so, we first have to
      select a variable $\texttt{var}$ that has not yet been assigned a value in $\texttt{Assignment}$ so far.
      This is done in line 5 using the function \texttt{arb} that selects an arbitrary variable
      from its input set.  
\item Next, we try to assign a $\texttt{value}$ to the selected variable $\texttt{var}$.  After assigning
      a $\texttt{value}$ to $\texttt{var}$, we immediately check whether this assignment would be consistent
      with the constraints using the function $\texttt{is\_consistent}$.
      If the partial $\texttt{Assignment}$ turns out to be consistent, the partial variable $\texttt{Assignment}$
      is extended to the new partial assignment \texttt{NewAss} that satisfies
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{NewAss[var] = value}.
      \\[0.2cm]
      Then, the function $\texttt{backtrack\_search}$ is called recursively to complete this new partial assignment.
      If this is successful, the resulting assignment is a solution that is returned.  Otherwise,
      the recursive call of $\texttt{backtrack\_search}$ will raise an exception.  This exception is muted 
      by the \texttt{try}-\texttt{except}-block that surrounds the call to $\texttt{backtrack\_search}$.  In that case, the
      \texttt{for}-loop generates a new $\texttt{value}$ that can be assigned to the variable
      $\texttt{var}$.  If all possible values have been tried and none was successful, the \texttt{for}-loop
      ends and we have to \blue{backtrack}, i.e.~we have to reassign one of the variables that have been
      assigned earlier.  This is done by raising a \texttt{Backtrack} exception.  This exception is then caught
      by one of the prior invocations of \texttt{backtrack\_search}.  If all variable assignments have been
      tried and none is successful, then the \texttt{Backtrack} exception propagates back to the function
      \texttt{solve}, which will return \texttt{None} in that case.
\end{enumerate}



\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  bgcolor       = sepia,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                ]{python3}
    def is_consistent(var, value, Assignment, Constraints):
        NewAssign      = Assignment.copy()
        NewAssign[var] = value
        return all(eval(f, NewAssign) for (f, Vs) in Constraints
                                      if  var in Vs and Vs <= NewAssign.keys()
                  )
\end{minted}
\vspace*{-0.3cm}
\caption{The definition of the function \texttt{is\_consistent}.}
\label{fig:is_consistent.py}
\end{figure}

We still need to discuss the implementation of the auxiliary function $\texttt{is\_consistent}$
shown in Figure \ref{fig:is_consistent.py}.  This function takes a variable $\texttt{var}$, a $\texttt{value}$, a partial 
$\texttt{Assignment}$ and a set of $\texttt{Constraints}$ as arguments.  It is assumed that $\texttt{Assignment}$ is
\blue{partially consistent} with respect to the set $\texttt{Constraints}$, i.e.~for every formula $\texttt{f}$
occurring in $\texttt{Constraints}$ such that
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{vars}(\texttt{f}) \subseteq \texttt{dom}(\texttt{Assignment})$
\\[0.2cm]
holds, the formula $\texttt{f}$ evaluates to $\texttt{True}$ given the $\texttt{Assignment}$.  The purpose of
$\texttt{is\_consistent}$ is to check, whether the extended assignment
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{NewAssign} \;\texttt{:=}\;\texttt{Assignment} \cup \{ \texttt{var} \mapsto \texttt{value} \}$
\\[0.2cm]
that assigns $\texttt{value}$ to the variable $\texttt{var}$ is still partially consistent with $\texttt{Constraints}$. 
To this end, the \texttt{for}-loop iterates over all formulas \texttt{f} in $\texttt{Constraints}$. 
However, we only have to check those formulas \texttt{f} that contain the variable $\texttt{var}$ and,
furthermore, have the property that
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Vars}(\texttt{f}) \subseteq \texttt{dom}(\texttt{NewAssign})$,
\\[0.2cm]
i.e.~all variables occurring in the formula $\texttt{f}$ need to have a value assigned in
$\texttt{NewAssign}$.  The reasoning is as follows:
\begin{enumerate}
\item If $\texttt{var}$ does not occur in the formula $\texttt{f}$, then adding $\texttt{var}$ to
      $\texttt{Assignment}$ cannot change the result of evaluating $\texttt{f}$ and as
      $\texttt{Assignment}$ is assumed to be partially consistent with respect to $\texttt{f}$, 
      $\texttt{NewAssign}$ is also partially consistent with respect to $\texttt{f}$.
\item If $\texttt{dom}(\texttt{NewAssign}) \not\subseteq \texttt{Vars}(\texttt{f})$, then $\texttt{f}$ can not
      be evaluated anyway. 

      Note that the domain of a variable assignment \texttt{A} can be computed with the expression 
      \texttt{A.keys()} since \texttt{A} is represented as a dictionary in \textsl{Python}.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    import extractVariables as ev
    
    def collect_variables(expr):
        return { var for var in ev.extractVars(expr)
                     if  var not in dir(__builtins__)
                     if  var not in ['and', 'or', 'not']
               }
\end{minted}
\vspace*{-0.3cm}
\caption{The function \texttt{collectVars}.}
\label{fig:collect_variables.py}
\end{figure}
Finally, let us discuss the function \texttt{collect\_variables} that is shown in \myFig{collect_variables.py}.
This function uses the module \texttt{extractVariables} that provides the function $\texttt{extractVars}(e)$.
This function takes a string $e$ that can be interpreted as a \textsl{Python} expression as its argument and
returns the set of all variables and function symbols occurring in the expression $e$.  As we only want to keep
the variable names, the function \texttt{collect\_variables} takes care to eliminate the function symbols.
This is done by making use of the fact that all function symbols that have been defined are members of the
list \texttt{dir(\_\_builtin\_\_)}.   It turns out that the keyword ``\texttt{and}'', ``\texttt{or}'', and
``\texttt{not}'' also need to be removed since they might also be members of the set returned by
$\texttt{extractVars}(\texttt{expr})$.

If we use the program discussed in this section, we can solve the 8 queens problem in about 22 milliseconds.
Hence, for the eight queens problem backtracking is more than a thousand times faster than brute force search.

\exercise
\index{zebra puzzle}
There are many different versions of the \href{https://en.wikipedia.org/wiki/Zebra_Puzzle}{\emph{zebra puzzle}}.  
The version below is taken from \href{https://en.wikipedia.org/wiki/Zebra_Puzzle}{\emph{Wikipedia}}.  The
puzzle reads as follows:
\begin{enumerate}[(a)]
\item There are five houses.
\item The Englishman lives in the red house.
\item The Spaniard owns the dog.
\item Coffee is drunk in the green house.
\item The Ukrainian drinks tea.
\item The green house is immediately to the right of the ivory house.
\item The Old Gold smoker owns snails.
\item Kools are smoked in the yellow house.
\item Milk is drunk in the middle house.
\item The Norwegian lives in the first house.
\item The man who smokes Chesterfields lives in the house next to the man with the fox.
\item Kools are smoked in the house next to the house where the horse is kept.
\item The Lucky Strike smoker drinks orange juice.
\item The Japanese smokes Parliaments.
\item The Norwegian lives next to the blue house.
\item Who drinks water? 
\item Who owns the zebra?
\end{enumerate}
In order to solve the puzzle, we also have to know the following facts:
\begin{itemize}
\item Each of the five houses is painted in a {\color{blue}different} colour.
\item The inhabitants of the five houses are of {\color{blue}different} nationalities, and
\item they own {\color{blue}different} pets,  drink {\color{blue}different} beverages, and
      smoke {\color{blue}different} brands of cigarettes. 
\end{itemize}
Formulate the zebra puzzle as a constraint satisfaction problem and solve the puzzle using the program
discussed in this section.
\eoxs


\section{Constraint Propagation}
\index{constraint propagation}
Once we have chosen a value for a variable, this choice influences the values that are still available for
other variables. 
For example, suppose that in order to solve the $n$ queens problem we place the queen in row one in the second
column, then no other queen can be placed in 
that column.   Furthermore, due to the constraints on diagonals, the queen in row two can not be placed
in any of the first three columns.  Abstractly, constraint propagation works as follows.
\begin{enumerate}
\item Before the search is started, we create a dictionary $\texttt{ValuesPerVar}$.  Initially, for every variable
      $\texttt{x}$,  the set
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{ValuesPerVar[x]}$ 
      \\[0.2cm]
      contains all values $\texttt{v}$ from the set $\texttt{Values}$.  As soon as we discover that assigning a
      value $\texttt{v}$ to the variable $\texttt{x}$ is inconsistent with the variable
      assignments that have already taken place for other variables, the value $\texttt{v}$ will be removed from the set
      $\texttt{ValuesPerVar[x]}$. 
\item As long as the given \ac{csp} is not solved,  we choose a variable $\texttt{x}$ that has not been assigned a
      value yet.  This variable is chosen using the \blue{most constrained variable}
      \index{most constrained variable heuristic} heuristic:  We choose a
      variable $\texttt{x}$ such that the number of values in the set
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{ValuesPerVar[x]}$ 
      \\[0.2cm]
      is minimal.  This is done because we have to
      find values for all variables.  If the current partial variable assignment can not be completed into a
      solution, then we want to find out this fact as soon as possible.  Therefore, we try to find the values
      for the most difficult variables first.  A variable is more difficult to get right if it has only a few
      values left that can be used to instantiate it.
\item Once we have picked a variable $\texttt{x}$, we next iterate over all values $\texttt{v}$ in
      $\texttt{ValuesPerVar[x]}$.  If the problem is hard, then it pays off to sort the values using the
      \blue{least constraining value}\index{least constraining value heuristic} heuristic:  The idea is that
      we compute for all values in  $\texttt{ValuesPerVar[x]}$ how much they constrain the values 
      of other variables.  The details of how this is done will be given later.  Once we have picked a value
      $\texttt{v}$ for the variable $\texttt{x}$ that puts the least constraints on the other variables, we
      assign this value $\texttt{v}$ to the variable $\texttt{x}$ and then we \blue{propagate} the consequences of this assignment: 
      \begin{enumerate}
      \item For every constraint $\texttt{f}$ that mentions only the variable $\texttt{x}$ and one other variable
            $\texttt{y}$ that has not yet been instantiated, we compute the set $\texttt{Legal}$ of those values from 
            $\texttt{ValuesPerVar[y]}$ that can be assigned to $\texttt{y}$ without violating the constraint
            $\texttt{f}$.
            
      \item Then, the set $\texttt{ValuesPerVar[y]}$ is updated to the set $\texttt{Legal}$ and we go back to
            step 2.
      \end{enumerate}
      Finally, we can explain how the \blue{least constraining value} heuristic orders the values:  For every value
      $\texttt{v}$ from the set $\texttt{ValuesPerVar[x]}$ the heuristic computes the \blue{shrinkage number},
      which is the number of values that have to be removed from the sets $\texttt{ValuesPerVar[y]}$ where
      $\texttt{y}$ is any variable that is different from $\texttt{x}$ and that have not yet been assigned.
      Then the different values are ordered ascendingly with respect to their shrinkage number.  Hence values
      with a low shrinkage number are tried before values with a higher shrinkage number.
\end{enumerate}
It turns out that elaborating the idea outlined above can enhance the performance of backtracking search
considerably.  \myFig{Constraint-Propagation-Solver.ipynb:solve} shows an implementation of 
\blue{constraint propagation}.  In addition to the ideas described above, this implementation takes care of
\blue{unary constraints}, i.e.~constraints that contain only a single variable, as these constraints can be
solved prior to the other constraints without backtracking.


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.3cm,
                xrightmargin  = 0.3cm,
              ]{python3}
    def solve(P, lcv=True):
        Variables, Values, Constraints = P
        Annotated    = { (f, collect_variables(f)) for f in Constraints }
        ValuesPerVar = { v: Values for v in Variables }
        UnaryConstrs = { (f, V) for f, V in Annotated if len(V) == 1 }
        OtherConstrs = { (f, V) for f, V in Annotated if len(V) >= 2 }
        try:
            for f, V in UnaryConstrs:
                var = arb(V)
                ValuesPerVar[var] = solve_unary(f, var, ValuesPerVar[var])
            return backtrack_search({}, ValuesPerVar, OtherConstrs, lcv)
        except Backtrack:
            return None
\end{minted}
\vspace*{-0.3cm}
\caption{Constraint Propagation.}
\label{fig:Constraint-Propagation-Solver.ipynb:solve}
\end{figure}

In order to implement constraint propagation, it is necessary to administer the values that can be used
to instantiate the different variables separately, i.e.~for every variable $\texttt{x}$ we need to know which
values are admissible for $\texttt{x}$.  To this end, we need a dictionary $\texttt{ValuesPerVar}$ that
contains the set of possible values for every variable $\texttt{x}$.  Initially, this dictionary assigns the
set $\texttt{Values}$ to every variable.  Next, we take care of the unary constraints and shrink these sets so
that the unary constraints are satisfied.  Then, whenever we assign a value to a variable $\texttt{x}$,  we
inspect those constraints that mention the variable $\texttt{x}$ and exactly one other yet unassigned variable
$\texttt{y}$ and shrink the set of values $\texttt{ValuesPerVar}[\texttt{y}]$ that can be assigned to this
variables $\texttt{y}$.  This process is called \blue{constraint propagation} and is described in more detail
below when we discuss the function \texttt{propagate}.
\begin{enumerate}
\item The function $\texttt{solve}$ receives a \ac{csp} \texttt{P} and a Boolean flag \texttt{lcv}.  
      The \ac{csp} \texttt{P} is first split into its
      three components and the constraints are annotated with the sets of variables occurring in them.
      These \blue{annotated constraints} are stored in the set \texttt{Annotated}.

      The flag \texttt{lcv} controls whether we order the values using the least constraining value heuristic.
      If this flag is \texttt{True}, the least constraining value heuristic is used.  Otherwise the values
      are ordered arbitrarily.
\item The most important data structure maintained by the function \texttt{solve} is the dictionary
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{ValuesPerVar}$.  
      \\[0.2cm]
      Given a variable $\texttt{v}$, this dictionary assigns the set of values that can be used to instantiate this
      variable.  Initially, this set is the same for all variables and is equal to $\texttt{Values}$.
\item In order to solve the unary constraints we first have to find them.
      The set $\texttt{UnaryConstrs}$ contains all those pairs $(\texttt{f}, \texttt{V})$ from the set of
      annotated constraints such that the set of variables $\texttt{V}$ contains just a
      single variable. 
\item Similarly, the set $\texttt{OtherConstrs}$ contains those constraints that involve two or more variables.
\item In order to solve the unary constraints, we iterate over all unary constraints and shrink the set of
      values associated with the variable occurring in the constraint as dictated by the constraint.
      This is done using the function $\texttt{solve\_unary}$.
\item Then, we start backtracking search using the function $\texttt{backtrack\_search}$.  
      Besides backtracking, the implementation of \texttt{backtrack\_search} that we present below
      implements the \blue{most constraint variable} heuristic and \blue{constraint propagation}.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def solve_unary(f, x, Values):
        Legal = { value for value in Values if eval(f, { x: value }) }
        if not Legal:
            raise Backtrack()
        return Legal
\end{minted}
\vspace*{-0.3cm}
\caption{Implementation of $\texttt{solve\_unary}$.}
\label{fig:Constraint-Propagation-Solver.ipynb:solve_unary}
\end{figure}

The function $\texttt{solve\_unary}$ shown in \myFig{Constraint-Propagation-Solver.ipynb:solve_unary} takes a unary
constraint $\texttt{f}$, the variable $\texttt{x}$ occurring in \texttt{f} and the set of values $\texttt{Values}$ that can be assigned to this
variable.  It returns the subset of values that can be substituted for the variable $\texttt{x}$
without violating the given constraint $\texttt{f}$.  If this set is empty, a \texttt{Backtrack} exception is
raised since in that case the given \ac{csp} is unsolvable.


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def backtrack_search(Assignment, ValuesPerVar, Constraints, lcv):
        if len(Assignment) == len(ValuesPerVar):
            return Assignment
        x = most_constrained_variable(Assignment, ValuesPerVar)
        if lcv and len(ValuesPerVar[x]) > 1:
            ValueList = least_constraining(x, ValuesPerVar, Assignment, Constraints)
        else:
            ValueList = ValuesPerVar[x]
        for v in ValueList: 
            try:
                NewValues = propagate(x, v, Assignment, Constraints, ValuesPerVar)
                NewAssign = Assignment.copy()
                NewAssign[x] = v
                return backtrack_search(NewAssign, NewValues, Constraints, lcv)
            except Backtrack:
                continue
        raise Backtrack()
\end{minted}
\vspace*{-0.3cm}
\caption{Implementation of $\texttt{backtrack\_search}$.}
\label{fig:Constraint-Propagation-Solver.ipynb:backtrack_search}
\end{figure}

The function $\texttt{backtrack\_search}$ shown in \myFig{Constraint-Propagation-Solver.ipynb:backtrack_search} is called with a
partial variable $\texttt{Assignment}$ that is guaranteed to be consistent, a dictionary
$\texttt{ValuesPerVar}$ associating every variable with the set of values that might be substituted for this variable, a
set of annotated $\texttt{Constraints}$, and a Boolean flag \texttt{lcv} that controls whether the
least constraining value heuristic is used.  It tries to complete $\texttt{Assignment}$ and thereby computes a
solution of the given \ac{csp}.  
\begin{enumerate}
\item If the partial $\texttt{Assignment}$ is already complete, i.e.~if it assigns a value to every variable, 
      then a solution to the given \ac{csp} has been found and this solution is returned.  As the
      dictionary $\texttt{ValuesPerVar}$ has an entry for every variable, its size is the same as the number of
      variables. Therefore, $\texttt{Assignment}$ is complete iff it has the same size as $\texttt{ValuesPerVar}$.
\item Otherwise, we choose a variable $\texttt{x}$ such that the number of values that can still be used to
      instantiate $\texttt{x}$ is minimal.  This strategy is known as the \blue{most constrained variable heuristic}. 
      The variable $\texttt{x}$ is computed using the function
      $\texttt{most\_constrained\_variable}$ that is shown in \myFig{Constraint-Propagation-Solver.ipynb:most_constrained_variable}.
      
      The logic behind choosing a maximally constrained variables is that these variables are the most
      difficult to get right.  If we have a partial assignment that is inconsistent, then we will discover this
      fact earlier if we try the most difficult variables first.  This might save us a lot of unnecessary
      backtracking later. 
\item Next, we try to find a value that can be assigned to the variable $\texttt{x}$.
      If the \blue{least constraining value heuristic} is used, we try those values first that have the
      smallest \blue{shrinkage number}.  Given a variable $\texttt{x}$, the shrinkage number for assigning the
      value $\texttt{v}$ to $\texttt{x}$ is the total number of values 
      that have to be removed from the sets $\texttt{ValuesPerVar[y]}$ when $\texttt{x}$ is set to $\texttt{v}$.
      Here $\texttt{y}$ ranges over all variables that are yet unassigned and are different from $\texttt{x}$.

      The function $\texttt{least\_constraining}$ returns a list of all values $\texttt{v}$
      that can be substituted for $\texttt{x}$.  This list is sorted ascendingly w.r.t.~the shrinkage number of
      $\texttt{v}$.  However, the function is only used if the flag $\texttt{lcv}$ is set.  The reason is that
      computing the shrinkage number is computationally quite expensive.  Therefore, this only pays off for hard
      problems.  If the flag is not set, the values are tried in an arbitrary order.

      Note that since
      $\texttt{ValuesPerVar[x]}$ is, in general, smaller than the set of all values of the \ac{csp},
      the \texttt{for}-loop in this version of backtracking search is more efficient than the corresponding
      \texttt{for}-loop in backtracking search discussed in the previous section. 
\item If assigning the value $\texttt{v}$ to the variable $\texttt{x}$ is consistent, we propagate the consequences
      of this assignment using the function $\texttt{propagate}$ shown in
      \myFig{Constraint-Propagation-Solver.ipynb:propagate}.
      This function updates the dictionary $\mathtt{ValuesPerVar}$ for all variables that are still unassigned.
\item Finally, the partial variable $\texttt{Assignment}$ is updated to include the assignment of 
      $\texttt{v}$ to $\texttt{x}$ and the recursive call to $\texttt{backtrack\_search}$ tries to complete this new
      assignment and thereby compute a solution to the given \ac{csp}. 
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def most_constrained_variable(Assignment, ValuesPerVar):
        Unassigned = { (x, len(U)) for x, U in ValuesPerVar.items()
                                   if  x not in Assignment
                     }
        minSize = min(lenU for _, lenU in Unassigned)
        return arb({ x for x, lenU in Unassigned if lenU == minSize })
\end{minted}
\vspace*{-0.3cm}
\caption{Finding a most constrained variable.}
\label{fig:Constraint-Propagation-Solver.ipynb:most_constrained_variable}
\end{figure}

\myFig{Constraint-Propagation-Solver.ipynb:most_constrained_variable} shows the implementation of the function
$\texttt{most\_constrained\_variable}$.  The function $\texttt{most\_constrained\_variable}$ takes a partial 
$\texttt{Assignment}$ and a dictionary $\texttt{ValuesPerVar}$ returning for all variables \texttt{x} the set
of values \texttt{ValuesPerVar[x]} that can be assigned to \texttt{x}.
\begin{enumerate}
\item First, this function computes the set of $\texttt{Unassigned}$ variables.  For every variable $\texttt{x}$ that
      has not yet been assigned a value in $\texttt{Assignment}$ this set contains the pair 
      $(\texttt{x}, \texttt{len}(U))$, where $U$ is the set of values that still might be tried for the variable  $\texttt{x}$.
\item Next, \texttt{minSize} is the minimum size of the sets \texttt{ValuesPerVar[x]} for all unassigned variables.
\item Finally, an arbitrary variable \texttt{x} that has only \texttt{minSize} values available is returned.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                 framesep      = 0.3cm, 
                 firstnumber   = 1,
                 bgcolor       = sepia,
                 numbers       = left,
                 numbersep     = -0.2cm,
                 xleftmargin   = 0.0cm,
                 xrightmargin  = 0.0cm,
               ]{python3}
    def least_constraining(x, ValuesPerVar, Assignment, Constraints):
        NumbersValues = []
        for value in ValuesPerVar[x]:
            ReducedValues = ValuesPerVar.copy()
            num_removed = shrinkage(x, value, Assignment, ReducedValues, Constraints)
            if num_removed != math.inf:
                NumbersValues.append( (num_removed, value) )
        NumbersValues.sort(key=lambda p: p[0])
        return [val for _, val in NumbersValues]\end{minted}
\vspace*{-0.3cm}
\caption{Finding the least constraining value.}
\label{fig:Constraint-Propagation-Solver.ipynb:least_constraining}
\end{figure} 

\myFig{Constraint-Propagation-Solver.ipynb:least_constraining} shows the implementation of the function 
$\texttt{least\_constraining}$.  This function takes four arguments.
\begin{enumerate}
\item $\texttt{x}$ is the variable that needs to be assigned a value next.
\item $\texttt{ValuesPerVar}$ is a dictionary.  For every variable $\texttt{y}$ that has not yet been assigned
      a value, $\texttt{ValuesPerVar[y]}$ is the set of values that can be assigned to $\texttt{y}$ without
      violating a constraint.
\item $\texttt{Assignment}$ is a partial variable assignment.
\item $\texttt{Constraints}$ is a set of annotated constraints.
\end{enumerate}
The purpose of the function $\texttt{least\_constraining}$ is to compute the shrinkage numbers of every value
$\texttt{v}$ in $\texttt{ValuesPerVar[x]}$ and to sort these values according to their shrinkage numbers.
To this end the list $\texttt{NumbersValues}$ is a list of pairs of the form $(n, v)$ where $v$ is a value and
$n$ is the shrinkage number of $v$.  To compute this list, the function $\texttt{shrinkage}$ computes the
number of values that had to be removed from all sets $\texttt{ValuesPerVar[y]}$ when $\texttt{x}$ is set to 
$\texttt{value}$.  The function $\texttt{shrinkage}$ returns the number $\texttt{math.inf}$ to signal the fact
that it has found the assignment $\{ \texttt{x} \mapsto \texttt{value} \}$ to be inconsistent.
After all shrinkage numbers have been computed, the list $\texttt{NumbersValues}$ is sorted ascendingly
w.r.t.~the shrinkage numbers.

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                 framesep      = 0.3cm, 
                 firstnumber   = 1,
                 bgcolor       = sepia,
                 numbers       = left,
                 numbersep     = -0.2cm,
                 xleftmargin   = 0.8cm,
                 xrightmargin  = 0.8cm,
               ]{python3}
    def shrinkage(x, value, Assignment, ValuesPerVar, Constraints):
        count     = 0   # number of values removed from ValuesPerVar
        BoundVars = set(Assignment.keys())
        for f, Vars in Constraints:
            if x in Vars:
                UnboundVars = Vars - BoundVars - { x }
                if len(UnboundVars) == 1:
                    y = arb(UnboundVars)
                    Legal = set()
                    for w in ValuesPerVar[y]:
                        NewAssign    = Assignment.copy()
                        NewAssign[x] = value
                        NewAssign[y] = w
                        if eval(f, NewAssign):
                            Legal.add(w)
                        else:
                            count += 1
                    if len(Legal) == 0:
                        return math.inf
                    ValuesPerVar[x] = Legal
        return count 
\end{minted}
\vspace*{-0.3cm}
\caption{Computing the shrinkage number.}
\label{fig:Constraint-Propagation-Solver.ipynb:shrinkage}
\end{figure}


The function $\texttt{shrinkage}$ shown in \myFig{Constraint-Propagation-Solver.ipynb:shrinkage} computes
the \blue{shrinkage numbers} of the given $\texttt{value}$ that is assigned to the variable $\texttt{x}$.
It takes the following inputs:
\begin{enumerate}[(a)]
\item $\texttt{x}$ is a variable and $\texttt{value}$ is the value that is assigned to the variable $\texttt{x}$.
\item $\texttt{Assignment}$ is a partial assignment that contains assignments for variables that are
      different from $\texttt{x}$.
\item $\texttt{ValuesPerVar}$ is a dictionary assigning sets of values to all variables.
\item $\texttt{Constraints}$ is a set of annotated constraints, i.e.~this set contains pairs of the form 
      $\texttt{(f, Vars)}$, where $\texttt{f}$ is a constraint and $\texttt{Vars}$ is the set of
      variables occurring in $\texttt{f}$.
\end{enumerate}
The function $\texttt{shrinkage}$ has to compute the number of values that have to be removed from the set
$\texttt{ValuesPerVar[y]}$ for all variables $\texttt{y}$ that are different from $\texttt{x}$ and that are
still unbound if the value $\mathtt{value}$ is assigned to the variable $\texttt{x}$.  The function is
implemented as follows: 
\begin{enumerate}
\item $\texttt{count}$ is the number of values that have to be removed form $\texttt{ValuesPerVar[y]}$ 
      for some variable $\texttt{y}$ if we set the variable $\texttt{x}$ to the value $\texttt{v}$.  
      Initially, $\texttt{count}$ is set to $0$.
\item $\texttt{BoundVars}$ is the set of those variable that already have a value assigned in $\texttt{Assignment}$.
\item Next, $\texttt{shrinkage}$ iterates over all  constraints $\texttt{f}$ such that the variable
      $\texttt{x}$ occurs in $\texttt{f}$.
\item $\texttt{UnboundVars}$ is the set of those variables occurring in $\texttt{f}$ that are different from
      $\texttt{x}$ and that do not yet have a value assigned.  These variables are called \blue{unbound variables} 
      since we still need to assign values for these variables.
\item If the set $\texttt{UnboundVars}$ contains just a single variable,
      the function $\texttt{arb}$ returns this variable $\texttt{y}$.
\item Now we have to find those values $\texttt{w}$ that can be assigned to $\texttt{y}$ without violating the
      constraint $\texttt{f}$.  Each time we find a value $\texttt{w}$ from $\texttt{ValuesPerVar[y]}$ such that
      the assignment
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{Assignment} \cup \{ \texttt{x} \mapsto \texttt{v}, \texttt{y} \mapsto \texttt{w} \}$
      \\[0.2cm]
      violates the constraint $\texttt{f}$, we increase the number $\texttt{count}$ since the value $\texttt{w}$
      has to be removed from $\texttt{ValuesPerVar[y]}$.  If the constraint $\texttt{f}$ is not violated,
      the value $\texttt{w}$ is added to the set $\texttt{Legal}$ of values that may be assigned to $\texttt{y}$.
\item If, after all values form $\texttt{NewValues[y]}$ have been tested, it turns out that
      $\texttt{Legal}$ is still empty, then this means that the constraint $\texttt{f}$ is inconsistent with
      assigning $\texttt{value}$  to the variable $\texttt{x}$ because 
      once we assign $\texttt{value}$ to $\texttt{x}$ we won't be able to find a value $\texttt{w}$ that can be
      assigned to $\texttt{y}$.  
      In this case the function $\texttt{shrinkage}$ returns $\texttt{math.inf}$ to signal this inconsistency.
\end{enumerate}


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def propagate(x, v, Assignment, Constraints, ValuesPerVar):
        ValuesDict = ValuesPerVar.copy()
        ValuesDict[x] = { v }
        BoundVars = set(Assignment.keys())
        for f, Vars in Constraints:
            if x in Vars:
                UnboundVars = Vars - BoundVars - { x }
                if len(UnboundVars) == 1:
                    y = arb(UnboundVars)
                    Legal = set()
                    for w in ValuesDict[y]:
                        NewAssign = Assignment.copy()
                        NewAssign[x] = v
                        NewAssign[y] = w
                        if eval(f, NewAssign):
                            Legal.add(w)
                    if len(Legal) == 0:
                        raise Backtrack()
                    ValuesDict[y] = Legal
        return ValuesDict
\end{minted}
\vspace*{-0.3cm}
\caption{Constraint Propagation.}
\label{fig:Constraint-Propagation-Solver.ipynb:propagate}
\end{figure}



\noindent
The function $\texttt{propagate}$ shown in \myFig{Constraint-Propagation-Solver.ipynb:propagate} implements
\blue{constraint propagation}.  It takes the following inputs:
\begin{enumerate}[(a)]
\item $\texttt{x}$ is a variable and $\texttt{v}$ is a value that is assigned to the variable $\texttt{x}$.
\item $\texttt{Assignment}$ is a partial assignment that contains assignments for variables that are
      different from $\texttt{x}$.
\item $\texttt{Constraints}$ is a set of annotated constraints, i.e.~this set contains pairs of the form 
      $\texttt{(f, Vars)}$, where $\texttt{f}$ is a constraint and $\texttt{Vars}$ is the set of
      variables occurring in $\texttt{f}$.
\item $\texttt{ValuesPerVar}$ is a dictionary assigning sets of values to all variables.
\end{enumerate}
The purpose of the function  $\texttt{propagate}$ is to restrict the values of variables different from
$\texttt{x}$  by propagating the consequences of setting $\texttt{x}$ to $\texttt{v}$.  To this end
the function $\texttt{propagate}$ updates the dictionary $\texttt{ValuesPerVar}$ by taking into account the
consequences of assigning the value $\texttt{v}$ to the variable $\texttt{x}$.  The implementation of
$\texttt{propagate}$ proceeds as follows.
\begin{enumerate}
\item Initially, we copy the Dictionary $\texttt{ValuesPerVar}$ to the dictionary
      $\mathtt{ValuesDict}$
\item As $\texttt{x}$ is assigned the value $\texttt{v}$, the corresponding entry in the dictionary
      $\texttt{ValuesDict}$ is changed accordingly. 
\item $\texttt{BoundVars}$ is the set of those variable that already have a value assigned.
\item Next, $\texttt{propagate}$ iterates over all  constraints $\texttt{f}$ such that the variable
      $\texttt{x}$ occurs in $\texttt{f}$.
\item $\texttt{UnboundVars}$ is the set of those variables occurring in $\texttt{f}$ that are different from
      $\texttt{x}$ and that do not yet have a value assigned.  
\item If there is exactly one unbound variable $\texttt{y}$ in the constraint $\texttt{f}$, then we can test
      those values that satisfy \texttt{f} and recompute the set $\texttt{ValuesDict[x]}$.
\item As the set $\texttt{UnboundVars}$ contains just a single variable in line 9,
      the function $\texttt{arb}$ returns this variable.
\item In order to recompute the set $\texttt{ValuesDict[y]}$,  all values $\texttt{w}$ in
      $\texttt{ValuesDict[y]}$ are tested.  The set $\texttt{Legal}$ contains all values $\texttt{w}$ that can
      be assigned to the variable $\texttt{y}$ without violating the constraint $\texttt{f}$.
\item If it turns out that $\texttt{Legal}$ is the empty set, then this means that the constraint
      $\texttt{f}$ is inconsistent with assigning the value $\texttt{v}$ to the variable
      $\texttt{x}$.  Hence, in this case the  search has to  \blue{backtrack}.
\item Otherwise, the set of admissible values for $\texttt{y}$ is updated to be the set $\texttt{Legal}$.
\item Finally, the dictionary $\texttt{ValuesDict}$ is returned.
\end{enumerate}
I have tested the program described in this section using the eight queens puzzle.  It takes about
18 milliseconds to find a solution if the least constraining value heuristic is not used.  I have also tested
it with the Zebra Puzzle described in a previous exercise.  It solves this puzzle in 21 milliseconds.  To
compare, the backtracking algorithm shown in the previous section takes roughly 10 seconds to solve this
puzzle.  Hence, for problems like the eight queens puzzle, the least constraining value heuristic does not pay
off.  However, for more complicated puzzles like Sudoku puzzles, the least constraining value heuristic speeds
up the computation.



\begin{table}[h]
  \centering
  \begin{tabular}{||c|c|c||c|c|c||c|c|c||}
    \hline
    \hline
      & 3 & 9 &   &   &   &   &   & 7 \\
    \hline
      &   &   & 7 &   &   & 4 & 9 & 2 \\
    \hline
      &   &   &   & 6 & 5 &   & 8 & 3 \\
    \hline
    \hline
      &   &   & 6 &   & 3 & 2 & 7 &   \\
    \hline
      &   &   &   & 4 &   & 8 &   &   \\
    \hline
    5 & 6 &   &   &   &   &   &   &   \\
    \hline
    \hline
      &   & 5 & 2 &   & 9 &   &   & 1 \\
    \hline
      & 2 & 1 &   &   &   &   & 4 &   \\
    \hline
    7 &   &   &   &   &   & 5 &   &   \\
    \hline
    \hline
  \end{tabular}
  \caption{A super hard sudoku from the magazine ``Zeit Online''.}
  \label{tab:sudoku}
\end{table}

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
               ]
    Sudoku = [ ['*',  3 ,  9 , '*', '*', '*', '*', '*',  7 ], 
               ['*', '*', '*',  7 , '*', '*',  4 ,  9 ,  2 ],
               ['*', '*', '*', '*',  6 ,  5 , '*',  8 ,  3 ],
               ['*', '*', '*',  6 , '*',  3 ,  2 ,  7 , '*'],
               ['*', '*', '*', '*',  4 , '*',  8 , '*', '*'],
               [ 5 ,  6 , '*', '*', '*', '*', '*', '*', '*'],
               ['*', '*',  5 ,  2 , '*',  9 , '*', '*',  1 ],
               ['*',  2 ,  1 , '*', '*', '*', '*',  4 , '*'],
               [ 7 , '*', '*', '*', '*', '*',  5 , '*', '*']
             ]
\end{Verbatim}
\vspace*{-0.3cm}
\caption{\textsl{Python} representation of the sudoku puzzle shown in Table \ref{tab:sudoku}.}
\label{fig:Sudoku.ipynb}
\end{figure}

\exercise
\index{sudoku}
Table \ref{tab:sudoku} on page \pageref{tab:sudoku} shows a \href{https://en.wikipedia.org/wiki/Sudoku}{sudoku}
that I have taken from the
\href{http://sudoku.zeit.de/cgi-bin/sudoku/sudoku_kd_app_2016.pl?action=level&kd_nr=24091123601092&year=2018&month=03&day=23&level=-c+5}{Zeit Online}
magazine.  This sudoku can be represented in \textsl{Python} as the list of lists that is shown in Figure
\ref{fig:Sudoku.ipynb}. 
\begin{enumerate}[(a)]
\item Implement a \textsl{Python} function \texttt{sudoku\_csp} that takes a description of a sudoku puzzle
      and returns a \ac{csp} such that the solution of the \ac{csp} is a solution of the given sudoku puzzle.
      A framework for turning a sudoku puzzle into a \ac{csp} can be found at:
      \\[0.2cm]
      \hspace*{1.3cm}
      \href{https://github.com/karlstroetmann/Artificial-Intelligence/blob/master/Python/2 Constraint
        Solver/Sudoku-Frame.ipynb}{https://github.com/karlstroetmann/Artificial-Intelligence/blob/master/\\
      \hspace*{2.6cm}  
          Python/2 Constraint Solver/Sudoku-Frame.ipynb}
\item Implement a function \texttt{find\_alternative} that takes two arguments:
  \begin{itemize}
  \item The first argument is sudoku \texttt{Puzzle}.
  \item The second argument is a \texttt{Solution} to this puzzle.
  \end{itemize}
  The function \texttt{find\_alternative} returns a \ac{csp} that has a solution if and only if there is a
  solution of the sudoku \texttt{Puzzle} that is different from the \texttt{Solution} that is given as the second argument.
\item Rewrite the \ac{csp} solver that has been discussed in this section so that instead of computing a single
      solution of a given \ac{csp} it computes the set of all solutions. 
      The solver can be found here:
      \\[0.2cm]
      \hspace*{1.3cm}
      \href{https://github.com/karlstroetmann/Artificial-Intelligence/blob/master/Python/2 Constraint Solver/Constraint-Propagation-Solver.ipynb}{https://github.com/karlstroetmann/Artificial-Intelligence/blob/master/\\
      \hspace*{2.6cm}  
        Python/2 Constraint Solver/Constraint-Propagation-Solver.ipynb}    
\end{enumerate}

\section{Consistency Checking$^*$ \label{sec:consistency}}
So far, the constraints in the constraints satisfaction problems discussed are either \blue{unary constraints} 
or \blue{binary constraints}:  A \blue{unary} constraint is a constraint $\texttt{f}$
such that the formula $\texttt{f}$ contains only one variable, while a \blue{binary} constraint
contains two variables.  If we have a constraint satisfaction problem that involves also constraints that
mention more than two variables, then the constraint propagation shown in the previous section is not
as effective as it is only used for a constraint $\texttt{f}$ if all but one variable of $\texttt{f}$ have been assigned.
For example, consider the \href{https://en.wikipedia.org/wiki/Verbal_arithmetic}{cryptarithmetic puzzle} shown
in \myFig{send-more-money.pdf}.  The idea is that the letters 
``$\texttt{S}$'', ``$\texttt{E}$'', ``$\texttt{N}$'', ``$\texttt{D}$'', ``$\texttt{M}$'', ``$\texttt{O}$'', ``$\texttt{R}$'', ``$\texttt{Y}$'' 
are interpreted as variables ranging over the set of decimal digits, i.e.~these variables can take values in
the set $\{0,1,2,3,4,5,6,7,8,9\}$.  Then, the string ``$\texttt{SEND}$'' is interpreted as a decimal number,
i.e.~it is interpreted as the number
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{S} \cdot 10^3 + \texttt{E} \cdot 10^2 + \texttt{N} \cdot 10^1 + \texttt{D} \cdot 10^0$.
\\[0.2cm]
The strings ``$\texttt{MORE}$ and ``$\texttt{MONEY}$'' are interpreted similarly. To make the problem
interesting, the assumption is that different variables have different values.  Furthermore, the
digits at the beginning of a number should be different from $0$.


\begin{figure}[!ht]
\centering
\framebox{\epsfig{file=Figures/send-more-money.pdf, scale=0.4}}

\caption{A cryptarithmetic puzzle}
\label{fig:send-more-money.pdf}
\end{figure}


\noindent
A na\"ive approach to solve this problem would be to code it as a constraint satisfaction problem that has,
among others,  the
following constraint:
\\[0.2cm]
\hspace*{0.0cm}
$   (\texttt{S} \cdot 10^3 + \texttt{E} \cdot 10^2 + \texttt{N} \cdot 10 + \texttt{D}) 
  + (\texttt{M} \cdot 10^3 + \texttt{O} \cdot 10^2 + \texttt{R} \cdot 10 + \texttt{E})
  = \texttt{M} \cdot 10^4 + \texttt{O} \cdot 10^3 + \texttt{N} \cdot 10^2 + \texttt{E} \cdot 10 + \texttt{Y}
$.
\\[0.2cm]
The problem with this constraint is that it involves far too many variables.  As this constraint can only be
checked when all the variables have values assigned to them, the backtracking search would essentially
boil down to a mere brute force search.  We would have 8 variables that each could take 10 different values and
hence we would have to test $10^{8}$ possible assignments. In order to do better, we have to perform the addition in Figure
 \ref{fig:send-more-money.pdf} column by column, just as it is taught in elementary school.
 \myFig{Crypto-Arithmetic.ipynb} shows how this can be implemented in \textsl{Python}.

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def crypto_csp():
        Digits       = { 'S', 'E', 'N', 'D', 'M', 'O', 'R', 'Y' }
        Variables    = Digits | { 'C1', 'C2', 'C3' }
        Values       = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }
        Constraints  = allDifferent(Digits)
        Constraints |= { '(D + E)      % 10 == Y', '(D + E)      // 10 == C1',
                         '(N + R + C1) % 10 == E', '(N + R + C1) // 10 == C2',
                         '(E + O + C2) % 10 == N', '(E + O + C2) // 10 == C3',
                         '(S + M + C3) % 10 == O', '(S + M + C3) // 10 == M'
                       }
        Constraints |= { 'S != 0', 'M != 0' }
        Constraints |= { 'C1 < 2', 'C2 < 2', 'C3 < 2' }
        return Variables, Values, Constraints
    
    def allDifferent(Variables):
        return { f'{x} != {y}' for x in Variables
                               for y in Variables 
                               if x < y 
           }
\end{minted}
\vspace*{-0.3cm}
\caption{Formulating ``$\texttt{SEND} + \texttt{MORE} = \texttt{MONEY}$'' as a \ac{csp}.}
\label{fig:Crypto-Arithmetic.ipynb}
\end{figure}

Notice that we have introduced three additional variables ``$\texttt{C1}$'', ``$\texttt{C2}$'', ``$\texttt{C3}$''. 
These variables serve as the \href{https://en.wikipedia.org/wiki/Carry_(arithmetic)}{carry digits}.  For
example, ``$\texttt{C1}$'' is the carry digit that we get when we do the addition of the last places of the two
numbers, i.e.~we have
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{D} + \texttt{E} = \texttt{C1} \cdot 10 + \texttt{Y}$.
\\[0.2cm]
This equation still contains four variables.  We can reduce it to two equations that each involve only three
variables as follows:
\\[0.2cm]
\hspace*{1.3cm}
$(\texttt{D} + \texttt{E})\; \texttt{\symbol{37}}\; 10 = \texttt{Y}$ \quad and \quad
$(\texttt{D} + \texttt{E}) \;\texttt{//}\; 10 = \texttt{C1}$.
\\[0.2cm]
Here, the symbol ``$\texttt{//}$'' denotes 
\href{https://en.wikipedia.org/wiki/Division_(mathematics)#Of_integers}{integer division}, 
e.g.~we have $7 \;\texttt{//}\; 3 = 2$ because $7 = 2 \cdot 3 + 1$.
If we solve the cryptarithmetic puzzle as coded in \myFig{Crypto-Arithmetic.ipynb} using the
constraint solver developed, then solving the puzzle takes about
a second on my computer.  The reason is that most constraints involve either three or four variables and
therefore the effects of constraint propagation kick only in when many variables have already been initialized.
However, we can solve the problem in less than 50 milliseconds if we add the following constraints for the 
variables ``$\texttt{C1}$'', ``$\texttt{C2}$'', ``$\texttt{C3}$'':
\\[0.2cm]
\hspace*{1.3cm}
\texttt{"C1 < 2", "C2 < 2", "C3 < 2"}.
\\[0.2cm]
Although these constraints are certainly true, the problem with this approach is that we would prefer our
constraint solver to figure out these constraints by itself.  After all, since $\texttt{D}$ and
$\texttt{E}$ are both less than $10$, there sum is obviously less than $20$ and hence the carry $\texttt{C1}$
has to be less than $2$.  This line of reasoning is known as \blue{consistency maintenance}:
Assume that the formula $f$ is a constraint and the set of variables occurring in $f$ has the form
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Var}(f) = \{ x \} \cup R$ \quad where $x \not\in R$,
\\[0.2cm]
i.e.~the variable $x$ occurs in the constraint $f$ and, furthermore, $R = \{y_1, \cdots, y_n\}$ is the set of
all variables occurring 
in $f$ that are different from $x$.  In addition, assume that we have a dictionary $\texttt{ValuesPerVar}$ such that
for every variable $y$, the dictionary entry $\texttt{ValuesPerVar}[y]$ is the set of values that can be substituted
for the variable $y$.  Formally, we define: 
\blue{A value $v$ is consistent for $x$ with respect to the constraint $f$} 
iff the partial assignment $\{ x \mapsto v \}$ can be extended to an assignment $A$ satisfying the constraint $f$,
i.e.~for every variable $y_i \in R$ we have to find a value $w_i \in \texttt{ValuesPerVar}[y_i]$ such that the resulting
assignment $A = \{ x \mapsto v, y_1 \mapsto w_1, \cdots, y_n \mapsto w_n \}$ satisfies the equations
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{eval}(f, A) = \texttt{True}$.
\\[0.2cm]
Here, the function $\texttt{eval}$ takes a formula $f$ and an assignment $A$ and evaluates $f$ using the
assignment $A$.  Now, \blue{consistency maintenance} works as follows. \index{consistency maintenance}
\begin{enumerate}
\item The dictionary $\texttt{ValuesPerVar}$ is initialized as follows:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{ValuesPerVar}[x] := \texttt{Values}$ \quad for all $x \in \texttt{Variables}$,
      \\[0.2cm]
      i.e.~initially every variable $x$ can take any value from the set of $\texttt{Values}$.
\item Next, the set $\texttt{UncheckedVariables}$ is initialized to the set of all $\texttt{Variables}$:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{UncheckedVariables} := \texttt{Variables}$.
\item As long as the set $\texttt{UncheckedVariables}$ is not empty, we remove one variable $x$ from this set:
      \\[0.2cm]
      \hspace*{1.3cm}
      $x := \texttt{UncheckedVariables}.\texttt{pop}()$
\item We iterate over all constraints $f$ such that $x$ occurs in $f$.  
      \begin{enumerate}
      \item For every value $v \in \texttt{ValuesPerVar}[x]$ we check whether $v$ is consistent with $f$.
      \item If the value $v$ is not consistent with $f$, then $v$ is removed from $\texttt{ValuesPerVar}[x]$.
            Furthermore, all variables \blue{connected} to $x$ are added to the set of 
            \index{connected variables} 
            $\texttt{UncheckedVariables}$.  Here we define y variable $y \not= x$ to be connected to $x$ if
            there is some constraint $f$ such that both $x$ and $y$ occur in $f$.  The reason is that some of
            their values might have become inconsistent by removing the value $v$ from
            $\texttt{ValuesPerVar}[x]$.
      \end{enumerate}
\item Once $\texttt{UncheckedVariables}$ is empty, the algorithm terminates.  Otherwise, we jump back to step 3
      and remove the next variable from the set $\texttt{UncheckedVariables}$.
\end{enumerate}
The algorithm terminates as every iteration removes either a variable from the set
$\texttt{UncheckedVariables}$ or it removes a value from one of the sets $\texttt{ValuesPerVar}[y]$ for some
variable $y$.  Although the set $\texttt{UncheckedVariables}$ can grow during the algorithm,  the union
\\[0.2cm]
\hspace*{1.3cm}
$\bigcup\limits_{x \in \texttt{Vars}} \texttt{ValuesPerVar}[x]$ 
\\[0.2cm]
can never grow:  Every time the set $\texttt{UncheckedVariables}$ grows,
for some variable $x$ the set
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{ValuesPerVar}[x]$ 
\\[0.2cm] 
shrinks.  As the sets $\texttt{ValuesPerVar}[x]$ are finite for all variables $x$, the set
$\texttt{UncheckedVariables}$ can only grow a finite number of times. 
Once the set $\texttt{UncheckedVariables}$ does not grow any more, every iteration of the algorithm removes one
variable from this set and hence the algorithm terminates eventually.

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm,
              ]{python3}
    def enforce_consistency(ValuesPerVar, Var2Formulas, Annotated, Connected):
        UncheckedVars = set(Var2Formulas.keys())
        while UncheckedVars:
            var         = UncheckedVars.pop()
            Constraints = Var2Formulas[var]
            Values      = ValuesPerVar[var]
            RemovedVals = set()
            for f in Constraints:
                OtherVars = Annotated[f] - { var }
                for value in Values:
                    if not exists_values(var, value, f, OtherVars, ValuesPerVar):
                        RemovedVals   |= { value }
                        UncheckedVars |= Connected[var]
            Remaining = Values - RemovedVals
            if not Remaining:
                raise Backtrack()
            ValuesPerVar[var] = Remaining
\end{minted}
\vspace*{-0.3cm}
\caption{Consistency maintenance in \textsc{Python}.}
\label{fig:Consistency-Solver.ipynb:enforce_consistency}
\end{figure}

\noindent
\myFig{Consistency-Solver.ipynb:enforce_consistency} shows how consistency maintenance can be implemented in
\textsl{Python}.
The function $\texttt{enforce\_consistency}$ takes four arguments.
\begin{enumerate}[(a)]
\item $\texttt{ValuesPerVar}$ is a dictionary associating the set of possible values with each variable.
\item $\texttt{Var2Formulas}$ is a dictionary.  For every variable $x$, $\texttt{Var2Formulas}[x]$ is
      the set of those constraints $f$ such that $x$ occurs in $f$.
\item $\texttt{Annotated}$ is a dictionary mapping constraints to the set of variables occurring in them, 
      i.e.~if $f$ is a constraint, then $\texttt{Annotated}[f]$ is the set of variables
      occurring in $f$.
\item $\texttt{Connected}$ is a dictionary that takes a variable $x$ and returns the set of all variables
      that are \blue{connected} to $x$ via a common constraint $f$, i.e.~we have $y \in \texttt{Connected}[x]$
      iff there exists a constraint $f$ such that both $x$ and $y$ occur in $f$ and, furthermore, $x \not= y$.
\end{enumerate}
The function $\texttt{enforce\_consistency}$ modifies the dictionary $\texttt{ValuesPerVar}$ so that once the
function has terminated, for every variable $x$ the values in the set
$\texttt{ValuesPerVar}[x]$ are consistent with the constraints for $x$.  The implementation works as follows:
\begin{enumerate}
\item Initially, all variables need to be checked for consistency.  Therefore, $\texttt{UncheckedVars}$
      is defined to be the set of all variables that occur in any of the constraints.
\item The \texttt{while}-loop iterates as long as there are still variables $x$ left in $\texttt{UncheckedVars}$
      such that the consistency of $\texttt{ValuesPerVar}[x]$ has not been established.
\item Next, a variable $\texttt{var}$ is selected and removed from $\texttt{UncheckedVars}$. 
\item $\texttt{Constraints}$ is the set of all constraints $f$ such that $\texttt{var}$ occurs in $f$.
\item $\texttt{Values}$ is the set of those values that can be assigned to the variable $\texttt{var}$.
\item $\texttt{RemovedVals}$ is the subset of those values that are found to be \blue{inconsistent} with some
      constraint. 
\item We iterate over all constraints $\texttt{f} \in \texttt{Constraints}$.
\item $\texttt{OtherVars}$ is the set of variables occurring in $\texttt{f}$ that are different from 
      the chosen variable $\texttt{var}$.
\item We iterate over all $\texttt{value} \in \texttt{Values}$ that can be substituted for the variable $\texttt{var}$
      and check whether $\texttt{value}$ is consistent with $\texttt{f}$.   To this end, we need to find values
      that can be assigned to the variables in the set $\texttt{OtherVars}$ such that $\texttt{f}$ evaluates as
      $\texttt{True}$.  This is checked using the function $\texttt{exists\_values}$.
\item If we do not find such values, then $\texttt{value}$ is inconsistent for the variables
      $\texttt{var}$ w.r.t.~$\texttt{f}$ and needs to be removed from the set 
      $\texttt{ValuesPerVar}[\texttt{var}]$.  Furthermore, all variables that are connected to
      $\texttt{var}$ have to be added to the set $\texttt{UncheckedVars}$.  The reason is that once a
      value is removed for the variable $\texttt{var}$, the value assigned to another variable $y$ occurring in a
      constraint that mentions both $\texttt{var}$ and $y$ might now become inconsistent.
\item If there are no consistent values for $\texttt{var}$ left, the problem is unsolvable and an exception is
      raised.
\item Otherwise, the set of values that are known to be consistent for \texttt{var} is stored
      as \\ $\texttt{ValuesPerVar}[\texttt{var}]$.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.8cm,
                xrightmargin  = 0.8cm,
              ]{python3}
    def exists_values(var, val, f, Vars, ValuesPerVar):
        Assignments = all_assignments(Vars, ValuesPerVar)
        return any(eval(f, extend(A, var, val)) for A in Assignments)
    
    def extend(A, x, v):
        B = A.copy()
        B[x] = v
        return B
    
    def all_assignments(Variables, ValuesPerVar):
        Variables = set(Variables) # turn frozenset into a set
        if not Variables:
            return [ {} ]  # list containing empty assignment
        var         = Variables.pop()
        Values      = ValuesPerVar[var]
        Assignments = all_assignments(Variables, ValuesPerVar)
        return [ extend(A, var, val) for A in Assignments 
                                     for val in ValuesPerVar[var]
               ]
\end{minted}
\vspace*{-0.3cm}
\caption{The implementation of $\texttt{exists\_value}$.}
\label{fig:Consistency-Solver.ipynb:exists_values}
\end{figure}

\noindent
\myFig{Consistency-Solver.ipynb:exists_values} shows the implementation of the function $\texttt{exists\_values}$ that
is used in the implementation of $\texttt{enforce\_consistency}$.  This function is called with five arguments.
\begin{enumerate}[(a)]
\item $\texttt{var}$ is variable.
\item $\texttt{val}$ is a value that is to be assigned to $\texttt{var}$.
\item $\texttt{f}$ is a constraint such that the variable $\texttt{var}$ occurs in $\texttt{f}$
\item $\texttt{Vars}$ is the set of all those other variables occurring in $\texttt{f}$, i.e.~the set of those
      variables that occur in $\texttt{f}$ but that are different from $\texttt{var}$. 
\item $\texttt{ValuesPerVar}$  is a dictionary associating the set of possible values with each variable.
\end{enumerate}
The function checks whether the partial assignment $\{ \texttt{var} \mapsto \texttt{val} \}$ can be
extended so that the constraint $\texttt{f}$ is satisfied.  To this end it needs to create the set of all
possible assignments.  This set is generated using the function $\texttt{all\_assignments}$.  This function
gets a set of variables $\texttt{Vars}$ and a dictionary that assigns to every variable $\texttt{var}$ in
$\texttt{Vars}$ the set of values that might be assigned to $\texttt{var}$.  It returns a list containing all
possible variable assignments.  The implementation proceeds as follows:
\begin{enumerate}
\item As the argument $\texttt{Variables}$ is a \texttt{frozenset} but we need to modify this set for the
      recursive call of \texttt{all\_assignments}, we transform the \texttt{frozenset} into a \texttt{set}.
\item If the set of variables $\texttt{Vars}$ is empty, the empty dictionary can serve as a mapping that 
      assigns a value to every variable in $\texttt{Vars}$.
\item Otherwise, we remove a variable $\texttt{var}$ from $\texttt{Vars}$ and get the set of $\texttt{Values}$
      that can be assigned to $\texttt{var}$.  
\item Recursively, we create the set of all $\texttt{Assignments}$ that associate values with the remaining 
      variables.
\item Finally, the set of all possible assignments is the set of all combinations of assigning a value 
      $\texttt{val} \in \texttt{Values}$ to $\texttt{var}$ and assigning the remaining variables according to 
      an assignment $\texttt{A} \in \texttt{Assignments}$.  Here we have to make use of the function
      \texttt{extend} that takes a dictionary \texttt{A}, a key \texttt{x} not occurring in \texttt{A} and a
      value \texttt{v} and returns a new dictionary that maps \texttt{x} to \texttt{v} and otherwise coincides
      with \texttt{A}.
\end{enumerate}
On one hand, consistency checking is a pre-processing step that creates a lot of overhead.\footnote{
  To be fair, the implementation shown in this section is far from optimal.  In particular, by remembering which
  combinations of variables and values work for a given formula, the overhead can be reduced significantly.  I have
  refrained from implementing this optimization because I did not want the code to get too complex.
}
Therefore, it might actually slow down the
solution of some constraint satisfaction problems that are easy to solve using just backtracking and
constraint propagation.  On the other hand, many difficult constraint satisfaction problems can not be solved
without consistency checking. 


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                 framesep      = 0.3cm, 
                 firstnumber   = 1,
                 bgcolor       = sepia,
                 numbers       = left,
                 numbersep     = -0.2cm,
                 xleftmargin   = 0.0cm,
                 xrightmargin  = 0.0cm,
               ]{python3}
    def solve(P):
        Variables, Values, Constraints = P
        VarsInConstrs  = union([ collect_variables(f) for f in Constraints ])
        MisspelledVars = (VarsInConstrs - Variables) | (Variables - VarsInConstrs)
        if MisspelledVars:
            print("Did you misspell any of the following Variables?")
            for v in MisspelledVars:
                print(v)
        ValuesPerVar = { x: Values for x in Variables }
        Annotated    = { f: collect_variables(f) for f in Constraints }
        UnaryConstrs = { (f, V) for f, V in Annotated.items() 
                                if  len(V) == 1 
                       }
        OtherConstrs = { (f, V) for f, V in Annotated.items() 
                                if  len(V) >= 2 
                       }
        Connected    = {}
        Var2Formulas = variables_2_formulas(OtherConstrs)
        for x in Variables:
            Connected[x] = union([ V for f, V in Annotated.items() 
                                     if  x in V 
                                 ]) - { x }
        try:
            for f, V in UnaryConstrs:
                var               = arb(V)
                ValuesPerVar[var] = solve_unary(f, var, ValuesPerVar[var])
            enforce_consistency(ValuesPerVar, Var2Formulas, Annotated, Connected)
            for x, Values in ValuesPerVar.items():
                print(f'{x}: {Values}')
            return backtrack_search({}, ValuesPerVar, OtherConstrs)
        except Backtrack:
            return None
\end{minted}
\vspace*{-0.3cm}
\caption{A constraint solver with consistency checking as a preprocessing step.}
\label{fig:Consistency-Solver.ipynb:solve}
\end{figure}

 \myFig{Consistency-Solver.ipynb:solve} shows how consistency checking is
integrated into a constraint solver as a pre-processing step.
The procedure $\texttt{solve}(P)$ takes a \blue{constraint satisfaction problem}
$P$ as input.  The function \texttt{solve} converts the CSP $P$ into an \blue{augmented} \ac{csp} where every
constraint $f$ is annotated with the variables occurring in $f$.  Furthermore, the function solve maintains the
following data structures: 
\begin{enumerate}
\item \texttt{VarsInConstrs} is the set of all variables occurring in any constraint.
\item \texttt{ValuesPerVar} is a dictionary mapping variables to sets of values.  For every variable $x$
      occurring in a constraint of $P$, the expression $\texttt{ValuesPerVar}(x)$ is the set of values that can
      be used to instantiate the variable $x$.  Initially, $\texttt{ValuesPerVar}(x)$ is set to
      \texttt{Values}, but as the search for a solution proceeds, the sets $\texttt{ValuesPerVar}(x)$ are
      reduced by removing any values that  cannot be part of a solution. 
\item \texttt{Annotated} is a dictionary.  For every constraint $f$ we have that $\texttt{Annotated}[f]$ is the
  set of all variables occurring in $f$. 
\item \texttt{UnaryConstrs} is a set of pairs of the form $(f, V)$ where $f$ is a constraint containing only a
      single variable and $V$ is the set containing just this variable. 
\item \texttt{OtherConstrs} is a set of pairs of the form $(f, V)$ where $f$ is a constraint containing more
      than one variable and $V$ is the set of all variables occurring in $f$. 
\item \texttt{Connected} is a dictionary mapping variables to sets of variables.  If $x$ is a variable, then
      $\texttt{Connected}[x]$ is the set of those variables $y$ such that there is a constraint $f$ that
      mentions both the variable $x$ and the variable $y$. 
\item \texttt{Var2Formulas} is a dictionary mapping variables to sets of formulas.  For every variable $x$,
      $\texttt{Var2Formulas}[x]$ is the set of all those non-unary constraints $f$ such that $x$ occurs in $f$. 
\end{enumerate}
After initializing these data structures, the unary constraints are immediately solved.  Then the
function \texttt{enforce\_consistency} performs  \blue{consistency maintenance}:  
Formally, we define: A value $v$ is \blue{consistent} for $x$ with respect to the constraint $f$
iff the partial assignment $\{ x \mapsto v \}$ can be extended to an assignment $A$ satisfying the constraint $f$,
i.e. for every variable $\texttt{y}_i$ occurring in $f$ there is a value $w_i \in \texttt{ValuesPerVar}[y]$ such that  
$$ \texttt{evaluate}\bigl(f, \{ x \mapsto v, y_1 \mapsto w_1, \cdots, y_n \mapsto w_n\}\bigr) = \texttt{True}. $$
The call to \texttt{enforce\_consistency} shrinks the sets $\texttt{ValuesPerVars}[x]$ until all values in
$\texttt{ValuesPerVars}[x]$ are consistent with respect to all constraints.

Finally, \texttt{backtrack\_search} is called to solve the remaining constraint satisfaction problem by the
means of both \blue{backtracking} and \blue{constraint propagation}. 


\section{Local Search$^*$}
There is another approach to solve constraint satisfaction problems.  This approach is known as
\blue{local search}.  The basic idea is simple: Given as constraint satisfaction problem 
$\mathcal{C}$ of the form 
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{P} := \langle \texttt{Variables}, \texttt{Values}, \texttt{Constraints} \rangle$,
\\[0.2cm] 
local search works as follows: \index{local search}
\begin{enumerate}
\item Use consistency checking as an optional pre-processing step.
\item Initialize the values of the variables in $\texttt{Variables}$ randomly.  
\item If all $\texttt{Constraints}$ are satisfied, return the solution.
\item For every  $x \in \texttt{Variables}$, count the number of \blue{unsatisfied} constraints that involve the
      variable $x$. 
\item Set $\texttt{maxNum}$ to be the maximum of these numbers, i.e.~$\texttt{maxNum}$ is the maximal number of
      unsatisfied constraints for any variable.
\item Compute the set $\texttt{maxVars}$ of those variables that have $\texttt{maxNum}$ unsatisfied constraints.
\item Randomly choose a variable $x$ from the set $\texttt{maxVars}$.
\item Find a value $d \in \texttt{Values}$ such that by assigning $d$ to the variable $x$, the number of
      unsatisfied constraints for the variable $x$ is minimized.  

      If there is more than one value $d$ with this property, choose the value $d$ randomly from those values
      that minimize the number of unsatisfied constraints.
\item Rinse and repeat until a solution is found.
\end{enumerate}


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                 framesep      = 0.3cm, 
                 firstnumber   = 1,
                 bgcolor       = sepia,
                 numbers       = left,
                 numbersep     = -0.2cm,
                 xleftmargin   = 0.0cm,
                 xrightmargin  = 0.0cm,
               ]{python3}
    def solve(P):
        Variables, Values, Constraints = P
        VarsInConstrs  = union([ collect_variables(f) for f in Constraints ])
        MisspelledVars = (VarsInConstrs - Variables) | (Variables - VarsInConstrs)
        if MisspelledVars:
            print("Did you misspell any of the following Variables?")
            for v in MisspelledVars:
                print(v)
        ValuesPerVar = { x: Values for x in Variables }
        Annotated    = { f: collect_variables(f) for f in Constraints }
        Connected    = {}
        Var2Formulas = variables_2_formulas(Annotated)
        for x in Variables:
            Connected[x] = union([V for f, V in Annotated.items() if x in V]) - {x}
        try:
            enforce_consistency(ValuesPerVar, Var2Formulas, Annotated, Connected)
        except Failure:
            return None
        return local_search(Variables, ValuesPerVar, Annotated)
\end{minted}
\vspace*{-0.3cm}
\caption{A constraint solver using local search.}
\label{fig:Local-Search.ipynb:solve}
\end{figure}

\myFig{Local-Search.ipynb:solve} shows the preprocessing step.  The function \texttt{solve} takes a constraint
satisfaction problem \texttt{P} as its argument and performs consistency checking similar to the algorithm
discussed in the previous section.  Following the preprocessing it calls the function \texttt{local\_search}
that solves the given \ac{csp}.

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                 framesep      = 0.3cm, 
                 firstnumber   = 1,
                 bgcolor       = sepia,
                 numbers       = left,
                 numbersep     = -0.2cm,
                 xleftmargin   = 0.0cm,
                 xrightmargin  = 0.0cm,
               ]{python3}
    def local_search(Variables, ValuesPerVar, Annotated):
        Variables = list(Variables) 
        Assign    = { x: random.choice(list(ValuesPerVar[x])) for x in Variables }
        iteration = 0
        lastVar   = arb(Variables)
        while True:
            Conflicts = [(numConflicts(x, Assign, Annotated), x) for x in Variables
                                                                 if  x != lastVar
                        ]
            maxNum, _ = Set.last(cast_to_Set(Conflicts))
            if maxNum == 0 and numConflicts(lastVar, Assign, Annotated) == 0:      
                print(f'Number of iterations: {iteration}')
                return Assign
            if iteration % 11 == 0:    # avoid infinite loop
                x = random.choice(Variables)
            else:     # choose var with max number of conflicts
                FaultyVars = [ var for (num, var) in Conflicts if  num == maxNum ]
                x = random.choice(FaultyVars)
            if iteration % 13 == 0:       # avoid infinite loop
                newVal = random.choice(list(ValuesPerVar[x])) 
            else:
                Conflicts = [ (numConflicts(x, extend(Assign, x, v), Annotated), v) 
                              for v in ValuesPerVar[x] 
                            ]
                minNum, _  = Set.first(cast_to_Set(Conflicts))
                ValuesForX = [ val for (n, val) in Conflicts if n == minNum ]
                newVal     = random.choice(ValuesForX)
            Assign[x]  = newVal
            lastVar    = x
            iteration += 1
\end{minted}
\vspace*{-0.3cm}
\caption{Implementation of local search.}
\label{fig:Local-Search.ipynb:local_search}
\end{figure}

\myFig{Local-Search.ipynb:local_search} shows an implementation of \blue{local search} in \textsl{Python}.  We
proceed to discuss this program line by line.
\begin{enumerate}
\item The function $\texttt{local\_search}$ takes three parameter.  
      \begin{enumerate}[(a)]
      \item \texttt{Variables} is the set of all variables occurring in the given \ac{csp}.
      \item \texttt{ValuesPerVar} is a dictionary.  For every variable \texttt{x}, \texttt{ValuesPerVar[x]} is
            the set of values that can be used to instantiate \texttt{x}.
      \item \texttt{Annotated} is a dictionary.  For every constraint $f$, $\texttt{Annotated}[f]$ is the set
            of variables occurring in $f$.
      \end{enumerate}
      If the computation is successful, $\texttt{local\_search}$ returns a dictionary that encodes a solution of the
      given \ac{csp} by mapping variables to values.
\item The set \texttt{Variables} is turned into a list.  This is necessary because the function
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{random.choice}(L)$
      \\[0.2cm]
      that is used to select a random element from $L$ expects its argument $L$ to be indexable, i.e.~for
      a number $k \in \{0, \cdots, \texttt{len}(L)-1\}$ the expression $L[k]$ needs to be defined.
\item \texttt{Assign} is a dictionary mapping all variables from the set \texttt{Variables} to values from the
      set \texttt{Values}.  Initially the values are assigned randomly.
\item The variable \texttt{iteration} counts the number of times that we have changed the assignment
      \texttt{Assign} by reassigning a variable.
\item If we have reassigned a variable $x$ in the last iteration of the loop, then we do not want to reassign
      it again in the next step since otherwise the program could get stuck in an infinite loop.  Therefore,
      the variable \texttt{lastVar} stores the variable that has been reassigned in the previous iteration.
      We will ensure that in the next iteration step, another variable is chosen for reassignment.
\item At the beginning of the \texttt{while} loop, we count the number of conflicts for all variables, i.e.~if
      $x$ is a variable that is different from the variable that has been reassigned in the last iteration,
      then we count the number of \blue{conflicts} \index{conflict} that $x$ causes.  This number is defined 
      as the number of constraints $f$ such that
      \begin{enumerate}
      \item $x$ occurs in $f$ and
      \item $f$ is not satisfied.
      \end{enumerate}
      This is done using the function \texttt{numConflicts} shown in \myFig{Local-Search.ipynb:numConflicts}.
      The list \texttt{Conflicts} defined in line 7 contains pairs of the form $(n, x)$ where $x$ is a
      variable and $n$ is the number of conflicts that this variable is involved in.
\item In line 10 the list \texttt{Conflicts} is turned into a set that is represented as an ordered binary set.
      This set is effectively a 
      priority queue that is ordered by the number of conflicts.  We pick the variable with the most conflicts
      from this set and store the number of conflicts in \texttt{maxNum}, i.e.~\texttt{maxNum} is the maximum
      number of conflicts that any variable is involved in.
\item Now if \texttt{maxNum} is $0$ and additionally the variable \texttt{lastVar} that is excluded from the
      computation of the set \texttt{Conflicts} has no conflicts, then the given \ac{csp} has been solved and
      the solution is returned.
\item Otherwise, the list  \texttt{FaultyVars} defined in line \texttt{17} collects those variables that have a maximal
      number of conflicts.  
\item In line \texttt{18} we choose a random variable \texttt{x} from this list as the variable to be
      reassigned.  However, this is only done ten out of eleven times.  In order to avoid running into an
      infinite loop where we keep changing the same variables, every $11^\textrm{th}$ iteration chooses
      \texttt{x} randomly.  This is controlled by the  test \texttt{iteration \% 11 == 0} in line 16.
\item Line \texttt{22} computes a list \texttt{Conflicts} that this time contains pairs of the form $(n, v)$ where $n$ 
      is the number of conflicts that the variable \texttt{x} would cause if we would assign the value $v$ to
      \texttt{x}.
\item Line \texttt{25} casts the list \texttt{Conflicts} into a set that is represented as an ordered binary tree.
      This ordered binary tree is used as a priority queue that is ordered by the number of conflicts.  We pick the
      smallest number of conflicts that any value $v$ causes when \texttt{x} is assigned to $v$.
\item \texttt{ValuesForX} is the list of those values that cause only \texttt{minNum} conflicts when assigned
      to \texttt{x}. 
\item \texttt{newVal} is a random element from this list that is then assigned to \texttt{x}.
      Again, this is only done twelve out of thirteen times.  The $13^\mathrm{th}$ time a random value is
      assigned to \texttt{x} instead. 
\item In line \texttt{29} we remember that we have reassigned \texttt{x} in this iteration so that we don't reassign
      \texttt{x} in the next iteration again.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                 framesep      = 0.3cm, 
                 firstnumber   = 1,
                 bgcolor       = sepia,
                 numbers       = left,
                 numbersep     = -0.2cm,
                 xleftmargin   = 0.0cm,
                 xrightmargin  = 0.0cm,
               ]{python3}
    def numConflicts(x, Assign, Annotated):
        NewAssign = Assign.copy()
        return len([ (f, V) for (f, V) in Annotated 
                            if x in V and not eval(f, NewAssign) 
                   ])
\end{minted}
\vspace*{-0.3cm}
\caption{The function $\texttt{numConflicts}$.}
\label{fig:Local-Search.ipynb:numConflicts}
\end{figure}

The function $\texttt{numConficts}$ is shown in \myFig{Local-Search.ipynb:numConflicts}.  If $x$ is a variable,
\texttt{Assign} is a variable assignment and \texttt{Annotated} is a list of pairs of the form $(f, V)$ where
$f$ is a constraint and $V$ is the set of variables occurring in $f$, then 
$\texttt{numConficts}(x,\texttt{Assign}, \texttt{Annotated})$
is the number of conflicts caused by the variable $x$.


Using the program discussed in this section, the n queens problem can be solved for a $\texttt{n} = 1000$ in
30 minutes.  As the memory requirements for local search are small, even much higher problem sizes can be
tackled if sufficient time is available.  It is a fact that often large problems, which are not inherently
difficult, can be solved much faster with local search than with any other algorithm.  
However, we have to note that local search is \blue{incomplete}:  If a
constraint satisfaction problem $\mathcal{P}$ has no solution, then local search loops forever.  Therefore, in
practise a \blue{dual approach} is used to solve a constraint satisfaction problem.  The constraint solver
starts two threads: The first search does local search, the second thread tries to solve the problem via some
refinement of backtracking.  The first thread that terminates wins.  The resulting algorithm is complete and,
for a solvable problem, will have a performance that is similar to the performance of local search.  If the
problem is unsolvable, this will  \blue{eventually} be discovered by backtracking.  Note, however, that the
constraint satisfaction problem is \href{https://en.wikipedia.org/wiki/NP-completeness}{NP-complete}.  Hence,
it is unlikely that there is an efficient algorithm that works \blue{always}.  However, today many practically
relevant constraint satisfaction problems can be solved in a reasonably short time. 

In this chapter we could only give a glimpse of the theory of constraint satisfaction problems.
For further details on the theory of \ac{csp}s, consult the book \blue{Constraint Processing} by Rina Dechter
\cite{dechter:2003}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "artificial-intelligence"
%%% End:
